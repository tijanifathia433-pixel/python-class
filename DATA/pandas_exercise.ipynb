{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02fe3f05",
   "metadata": {},
   "source": [
    "# Titanic Dataset - Comprehensive Practice Exercises\n",
    "\n",
    "## ðŸ“Š Data Source & Quick Setup\n",
    "\n",
    "### Download the Dataset\n",
    "```python\n",
    "# Method 1: Direct download from URL\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "titanic_df = pd.read_csv(url)\n",
    "\n",
    "# Method 2: From seaborn (if installed)\n",
    "import seaborn as sns\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# Method 3: Manual download\n",
    "# Download from: https://www.kaggle.com/c/titanic/data\n",
    "# titanic_df = pd.read_csv('titanic.csv')\n",
    "```\n",
    "\n",
    "### Dataset Overview\n",
    "The Titanic dataset contains information about 891 passengers on the Titanic with the following columns:\n",
    "- **Survived**: Survival (0 = No, 1 = Yes)\n",
    "- **Pclass**: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "- **Sex**: Gender\n",
    "- **Age**: Age in years\n",
    "- **SibSp**: # of siblings/spouses aboard\n",
    "- **Parch**: # of parents/children aboard\n",
    "- **Ticket**: Ticket number\n",
    "- **Fare**: Passenger fare\n",
    "- **Cabin**: Cabin number\n",
    "- **Embarked**: Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Problem Statements - Organized by Difficulty\n",
    "\n",
    "## ðŸŸ¢ Level 1: Basic Data Exploration & Cleaning\n",
    "\n",
    "### Exercise 1.1: Initial Data Inspection\n",
    "```python\n",
    "# Problem Statement:\n",
    "\"\"\"\n",
    "1. Load the Titanic dataset and display the first 10 rows\n",
    "2. Get basic information about the dataset (shape, columns, data types)\n",
    "3. Display summary statistics for numerical columns\n",
    "4. Check for missing values in each column\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Exercise 1.2: Data Cleaning Fundamentals\n",
    "```python\n",
    "\"\"\"\n",
    "1. Handle missing values:\n",
    "   - Fill missing 'Age' values with the median age\n",
    "   - Fill missing 'Embarked' with the most frequent value\n",
    "   - Drop the 'Cabin' column (too many missing values)\n",
    "2. Create a new column 'FamilySize' = SibSp + Parch + 1\n",
    "3. Convert 'Sex' to numerical values (male: 0, female: 1)\n",
    "4. Create age groups: Child (0-12), Teen (13-19), Adult (20-59), Senior (60+)\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Exercise 1.3: Basic Analysis\n",
    "```python\n",
    "\"\"\"\n",
    "1. What is the overall survival rate?\n",
    "2. How many passengers were in each class?\n",
    "3. What is the average age of passengers?\n",
    "4. Which embarkation port had the most passengers?\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŸ¡ Level 2: Intermediate Analysis & Visualization\n",
    "\n",
    "### Exercise 2.1: Demographic Analysis\n",
    "```python\n",
    "\"\"\"\n",
    "1. Analyze survival by gender:\n",
    "   - What percentage of women survived?\n",
    "   - What percentage of men survived?\n",
    "   - Create a bar chart comparing survival rates by gender\n",
    "\n",
    "2. Analyze survival by passenger class:\n",
    "   - Calculate survival rates for each class\n",
    "   - Visualize with a stacked bar chart\n",
    "   - Which class had the highest survival rate?\n",
    "\n",
    "3. Age analysis:\n",
    "   - What is the average age of survivors vs non-survivors?\n",
    "   - Create a histogram of ages for survivors and non-survivors\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Exercise 2.2: Family & Fare Analysis\n",
    "```python\n",
    "\"\"\"\n",
    "1. Family size impact:\n",
    "   - Create family size categories: Alone, Small (2-4), Large (5+)\n",
    "   - Calculate survival rate for each family size category\n",
    "   - Does traveling with family increase survival chances?\n",
    "\n",
    "2. Fare analysis:\n",
    "   - What is the average fare for each passenger class?\n",
    "   - Create fare categories: Low (<10), Medium (10-50), High (>50)\n",
    "   - Analyze survival rates by fare categories\n",
    "\n",
    "3. Combined factors:\n",
    "   - Find survival rate for women in 1st class vs men in 3rd class\n",
    "   - What was the survival rate for children in each class?\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Exercise 2.3: Data Transformation\n",
    "```python\n",
    "\"\"\"\n",
    "1. Create a new DataFrame that includes:\n",
    "   - Passenger name (from Name column - extract titles: Mr, Mrs, Miss, etc.)\n",
    "   - Age group\n",
    "   - Family size category\n",
    "   - Fare category\n",
    "   - Survival status\n",
    "\n",
    "2. Calculate survival rates by title (Mr, Mrs, Miss, Master, etc.)\n",
    "3. Find the most common ticket for each passenger class\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”´ Level 3: Advanced Analysis & Insights\n",
    "\n",
    "### Exercise 3.1: Complex Grouping & Aggregation\n",
    "```python\n",
    "\"\"\"\n",
    "1. Create a comprehensive summary table showing:\n",
    "   - Count of passengers\n",
    "   - Survival rate\n",
    "   - Average age\n",
    "   - Average fare\n",
    "   For each combination of: Pclass Ã— Sex Ã— Embarked\n",
    "\n",
    "2. Calculate the survival probability for:\n",
    "   - A 30-year-old female in 1st class\n",
    "   - A 45-year-old male in 3rd class\n",
    "   - A child (under 12) in 2nd class\n",
    "\n",
    "3. Find the 5 most expensive tickets and analyze their survival rate\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Exercise 3.2: Correlation & Pattern Finding\n",
    "```python\n",
    "\"\"\"\n",
    "1. Calculate correlation matrix for numerical features\n",
    "2. Identify which factors are most strongly correlated with survival\n",
    "3. Create a pivot table showing survival rates by:\n",
    "   - Age groups vs Passenger class\n",
    "   - Family size vs Gender\n",
    "   - Embarkation port vs Passenger class\n",
    "\n",
    "4. Find interesting patterns:\n",
    "   - Were there any families where some members survived and others didn't?\n",
    "   - What was the survival rate of passengers traveling alone?\n",
    "   - Did having a higher fare within the same class increase survival chances?\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Exercise 3.3: Feature Engineering\n",
    "```python\n",
    "\"\"\"\n",
    "1. Extract titles from names (Mr, Mrs, Miss, Master, etc.)\n",
    "2. Create a 'IsChild' column (Age < 12)\n",
    "3. Create a 'IsAlone' column (FamilySize == 1)\n",
    "4. Create fare per person (Fare / FamilySize)\n",
    "5. Create age Ã— class interaction term\n",
    "6. Bin ages into quantiles (equal number of passengers in each age group)\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ† Level 4: Real-World Scenarios\n",
    "\n",
    "### Exercise 4.1: Complete Data Analysis Report\n",
    "```python\n",
    "\"\"\"\n",
    "Create a comprehensive analysis that answers these business questions:\n",
    "\n",
    "1. **Passenger Profile Analysis:**\n",
    "   - What was the typical passenger profile?\n",
    "   - How did passenger demographics vary by class?\n",
    "\n",
    "2. **Survival Factors Investigation:**\n",
    "   - What were the key factors that influenced survival?\n",
    "   - Was the \"women and children first\" policy followed?\n",
    "   - How did wealth (as indicated by class and fare) affect survival?\n",
    "\n",
    "3. **Recommendations:**\n",
    "   - If you were designing safety protocols based on this data, what would you recommend?\n",
    "   - What passenger characteristics would you prioritize for lifeboat access?\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Exercise 4.2: Predictive Features Preparation\n",
    "```python\n",
    "\"\"\"\n",
    "Prepare the dataset for machine learning by:\n",
    "\n",
    "1. Handling all missing values appropriately\n",
    "2. Encoding categorical variables\n",
    "3. Creating new meaningful features\n",
    "4. Removing irrelevant columns\n",
    "5. Normalizing numerical features\n",
    "6. Creating a clean, analysis-ready dataset\n",
    "\n",
    "Final dataset should have these features:\n",
    "- Pclass, Sex, Age, SibSp, Parch, Fare, Embarked\n",
    "- FamilySize, IsAlone, Title, AgeGroup, FarePerPerson\n",
    "- (All properly encoded and scaled)\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Exercise 4.3: Data Storytelling\n",
    "```python\n",
    "\"\"\"\n",
    "Create a compelling data story with visualizations:\n",
    "\n",
    "1. **The Tragedy in Numbers:** Overall statistics and key figures\n",
    "2. **Survival Inequalities:** How different factors affected survival\n",
    "3. **Passenger Stories:** Find and highlight interesting individual cases\n",
    "4. **Lessons Learned:** Key takeaways from the data\n",
    "\n",
    "Required visualizations:\n",
    "- Survival rate by different demographics\n",
    "- Distribution of passengers across different categories\n",
    "- Correlation heatmap\n",
    "- Age distribution of survivors vs non-survivors\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "## ðŸŽ¯ Expected Learning Outcomes\n",
    "\n",
    "After completing these exercises, students should be able to:\n",
    "\n",
    "### Technical Skills\n",
    "- Handle real-world messy data with missing values\n",
    "- Perform advanced data filtering and grouping\n",
    "- Create meaningful data visualizations\n",
    "- Extract insights from complex datasets\n",
    "- Prepare data for machine learning\n",
    "\n",
    "### Analytical Skills\n",
    "- Formulate and test hypotheses\n",
    "- Identify patterns and correlations\n",
    "- Draw meaningful conclusions from data\n",
    "- Communicate findings effectively\n",
    "- Think critically about data quality and biases\n",
    "\n",
    "### Business Understanding\n",
    "- Translate business questions into data analysis\n",
    "- Provide actionable recommendations\n",
    "- Understand the ethical implications of data analysis\n",
    "- Create compelling data stories\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’¡ Pro Tips for Students\n",
    "\n",
    "1. **Always start with data understanding** - explore before analyzing\n",
    "2. **Document your assumptions** - especially for handling missing data\n",
    "3. **Validate your findings** - cross-check with multiple approaches\n",
    "4. **Consider the context** - historical and social factors matter\n",
    "5. **Visualize effectively** - choose the right chart for your message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8edebdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Order ID Product Name  Quantity  Unit Price  Total Revenue  \\\n",
      "0      1001      Monitor         3          50            150   \n",
      "1      1002      USB Hub         1          75             75   \n",
      "2      1003   Smartphone         4         250           1000   \n",
      "3      1004   Headphones         2         150            300   \n",
      "4      1005      Monitor         8          50            400   \n",
      "\n",
      "  Customer Location Product Category  \n",
      "0             Enugu      Accessories  \n",
      "1     Port Harcourt        Computers  \n",
      "2             Abuja      Accessories  \n",
      "3             Abuja        Computers  \n",
      "4            Ibadan      Electronics  \n",
      "âœ… Dataset saved as 'sample_sales_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate sample dataset\n",
    "num_rows = 50\n",
    "order_ids = np.arange(1001, 1001 + num_rows)\n",
    "products = np.random.choice(\n",
    "    [\"Wireless Mouse\", \"Keyboard\", \"Laptop Stand\", \"USB Hub\", \"Headphones\", \n",
    "     \"Webcam\", \"Monitor\", \"Smartphone\", \"Tablet\", \"Charger\"], \n",
    "    size=num_rows\n",
    ")\n",
    "quantities = np.random.randint(1, 10, size=num_rows)\n",
    "unit_prices = np.random.choice([15, 25, 50, 75, 100, 150, 200, 250], size=num_rows)\n",
    "total_revenue = quantities * unit_prices\n",
    "locations = np.random.choice(\n",
    "    [\"Lagos\", \"Abuja\", \"Kano\", \"Port Harcourt\", \"Ibadan\", \"Enugu\"], size=num_rows\n",
    ")\n",
    "categories = np.random.choice(\n",
    "    [\"Electronics\", \"Accessories\", \"Computers\", \"Mobile Devices\"], size=num_rows\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Order ID\": order_ids,\n",
    "    \"Product Name\": products,\n",
    "    \"Quantity\": quantities,\n",
    "    \"Unit Price\": unit_prices,\n",
    "    \"Total Revenue\": total_revenue,\n",
    "    \"Customer Location\": locations,\n",
    "    \"Product Category\": categories\n",
    "})\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Save as CSV\n",
    "df.to_csv(\"sample_sales_dataset.csv\", index=False)\n",
    "print(\"âœ… Dataset saved as 'sample_sales_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5faee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Sample data\n",
    "products = ['Laptop', 'Phone', 'Tablet', 'Headphones', 'Charger', \n",
    "            'Monitor'\"Wireless Mouse\", \"Keyboard\", \"Laptop Stand\", \"Webcam\"]\n",
    "categories = ['Electronics', 'Accessories', 'Gadgets', \"Computers\", \"Mobile Devices\"]\n",
    "locations = ['Lagos', 'Abuja', 'Kano', 'Port Harcourt', 'Ibadan', \"Enugu\"]\n",
    "\n",
    "data = {\n",
    "    'Order_ID': [f\"ORD{1000+i}\" for i in range(50)],\n",
    "    'Product_Name': np.random.choice(products, 50),\n",
    "    'Quantity': np.random.randint(1, 10, 50),\n",
    "    'Unit_Price': np.random.randint(5000, 200000, 50),\n",
    "    'Customer_Location': np.random.choice(locations, 50),\n",
    "    'Product_Category': np.random.choice(categories, 50)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['Total_Revenue'] = df['Quantity'] * df['Unit_Price']\n",
    "\n",
    "# Save to CSV for import into MySQL\n",
    "df.to_csv(\"sample_sales_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a575786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"08023256300\",\n",
    "    database=\"sales_db\",\n",
    "    allow_local_infile=True  # ðŸ‘ˆ THIS IS IMPORTANT\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "LOAD DATA LOCAL INFILE 'C:/Users/USER/Desktop/python/DATA/sample_sales_data.csv'\n",
    "INTO TABLE sales\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "IGNORE 1 ROWS\n",
    "(Order_ID, Product_Name, Quantity, Unit_Price, Customer_Location, Product_Category, Total_Revenue)\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
