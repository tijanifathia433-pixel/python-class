{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4782b150",
   "metadata": {},
   "source": [
    "### Pandas Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb308e6d",
   "metadata": {},
   "source": [
    "Pandas = Python’s spreadsheet on steroids\n",
    "A free, open-source library that gives you two super-powered objects:\n",
    "Series = a single column of labelled data (any type).\n",
    "DataFrame = a whole table of Series that share an index (rows + columns).\n",
    "In one sentence:\n",
    "“Import messy data, clean it, slice it, join it, group it, time-series it, and export it—all in a couple of lines.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18329168",
   "metadata": {},
   "source": [
    "To get started with pandas, you will need to get comfortable with its two workhorse data structures: Series and DataFrame. While they are not a universal solution for every problem, they provide a solid foundation for a wide variety of data tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c320fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3503ce11",
   "metadata": {},
   "source": [
    "To get started with pandas, you will need to get comfortable with its two workhorse data structures: Series and DataFrame. While they are not a universal solution for every problem, they provide a solid foundation for a wide variety of data tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5a7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff0caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([4, 7, -5, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a927f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a2f79",
   "metadata": {},
   "source": [
    "You can get the array representation and index object of the Series via its array and index attributes, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d950f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d088b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c45789",
   "metadata": {},
   "source": [
    "Often, you'll want to create a Series with an index identifying each data point with a label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2202ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 = pd.Series([4, 7, -5, 3], index=[\"d\", \"b\", \"a\", \"c\"])\n",
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df27510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c07167",
   "metadata": {},
   "source": [
    "Compared with NumPy arrays, you can use labels in the index when selecting single values or a set of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b26352",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187904ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[\"d\"] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[[\"c\", \"a\", \"d\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a749f53e",
   "metadata": {},
   "source": [
    "Using NumPy functions or NumPy-like operations, such as filtering with a Boolean array, scalar multiplication, or applying math functions, will preserve the index-value link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b308d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[obj2 > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "373d252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b0720",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(obj2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9a623c",
   "metadata": {},
   "source": [
    "Another way to think about a Series is as a fixed-length, ordered dictionary, as it is a mapping of index values to data values. It can be used in many contexts where you might use a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48fcbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"b\" in obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aebfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"e\" in obj2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13437e83",
   "metadata": {},
   "source": [
    "Should you have data contained in a Python dictionary, you can create a Series from it by passing the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9294b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = {\"Ohio\": 35000, \"Texas\": 71000, \"Oregon\": 16000, \"Utah\": 5000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c735d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj3 = pd.Series(sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db98051",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91259462",
   "metadata": {},
   "source": [
    "A Series can be converted back to a dictionary with its to_dict method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4136c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ceb08f",
   "metadata": {},
   "source": [
    "When you are only passing a dictionary, the index in the resulting Series will respect the order of the keys according to the dictionary's keys method, which depends on the key insertion order. You can override this by passing an index with the dictionary keys in the order you want them to appear in the resulting Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"California\", \"Ohio\", \"Oregon\", \"Texas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj4 = pd.Series(sdata, index=states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8681b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fb126a",
   "metadata": {},
   "source": [
    "Here, three values found in sdata were placed in the appropriate locations, but since no value for \"California\" was found, it appears as NaN (Not a Number), which is considered in pandas to mark missing or NA values. Since \"Utah\" was not included in states, it is excluded from the resulting object.\n",
    "\n",
    "I will use the terms “missing,” “NA,” or “null” interchangeably to refer to missing data. The isna and notna functions in pandas should be used to detect missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(obj4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efb022",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.notna(obj4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f424e",
   "metadata": {},
   "source": [
    "A useful Series feature for many applications is that it automatically aligns by index label in arithmetic operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afad5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddafe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac31f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj3 + obj4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a078c",
   "metadata": {},
   "source": [
    "Data alignment features will be addressed in more detail later. If you have experience with databases, you can think about this as being similar to a join operation.\n",
    "\n",
    "Both the Series object itself and its index have a name attribute, which integrates with other areas of pandas functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd06cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj4.name = \"population\"\n",
    "obj4.index.name = \"state\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95085bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c02c82",
   "metadata": {},
   "source": [
    "A Series’s index can be altered in place by assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fea50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487bd345",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.index = [\"Bob\", \"Steve\", \"Jeff\", \"Ryan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3f5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e928a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41bb7b62",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "A DataFrame represents a rectangular table of data and contains an ordered, named collection of columns, each of which can be a different value type (numeric, string, Boolean, etc.). The DataFrame has both a row and column index; it can be thought of as a dictionary of Series all sharing the same index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05596409",
   "metadata": {},
   "source": [
    "There are many ways to construct a DataFrame, though one of the most common is from a dictionary of equal-length lists or NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa2f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\"],\n",
    "        \"year\": [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "        \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
    "frame = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fe23ec",
   "metadata": {},
   "source": [
    "The resulting DataFrame will have its index assigned automatically, as with Series, and the columns are placed according to the order of the keys in data (which depends on their insertion order in the dictionary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3900d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6f49b",
   "metadata": {},
   "source": [
    "For large DataFrames, the head method selects only the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ec5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d70e06",
   "metadata": {},
   "source": [
    "Similarly, tail returns the last five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ccb3c",
   "metadata": {},
   "source": [
    "If you specify a sequence of columns, the DataFrame’s columns will be arranged in that order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7fdfb4",
   "metadata": {},
   "source": [
    "If you pass a column that isn’t contained in the dictionary, it will appear with missing values in the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bfc2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2 = pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\", \"debt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f8b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fc132a",
   "metadata": {},
   "source": [
    "A column in a DataFrame can be retrieved as a Series either by dictionary-like notation or by using the dot attribute notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44309701",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c111247",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2399c4",
   "metadata": {},
   "source": [
    "Columns can be modified by assignment. For example, the empty debt column could be assigned a scalar value or an array of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06ac2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2.loc[1, \"debt\"] = 15.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd718331",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb8cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2[\"debt\"] = np.arange(6.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7170c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8388d152",
   "metadata": {},
   "source": [
    "When you are assigning lists or arrays to a column, the value’s length must match the length of the DataFrame. If you assign a Series, its labels will be realigned exactly to the DataFrame’s index, inserting missing values in any index values not present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07134b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.Series([-1.2, -1.5, -1.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb3f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2[\"debt\"] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c08a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55ef4ec",
   "metadata": {},
   "source": [
    "Assigning a column that doesn’t exist will create a new column.\n",
    "\n",
    "The del keyword will delete columns like with a dictionary. As an example, I first add a new column of Boolean values where the state column equals \"Ohio\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a332cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2[\"eastern\"] = frame2[\"state\"] == \"Ohio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b269eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fe2cc5",
   "metadata": {},
   "source": [
    "Note: New columns cannot be created with the frame2.eastern dot attribute notation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5904ce0b",
   "metadata": {},
   "source": [
    "The del method can then be used to remove this column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "del frame2[\"eastern\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5695e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e27f6eb",
   "metadata": {},
   "source": [
    "Another common form of data is a nested dictionary of dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0753688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = {\"Ohio\": {2000: 1.5, 2001: 1.7, 2002: 3.6},\"Nevada\": {2001: 2.4, 2002: 2.9}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5273c",
   "metadata": {},
   "source": [
    "If the nested dictionary is passed to the DataFrame, pandas will interpret the outer dictionary keys as the columns, and the inner keys as the row indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f036ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3 = pd.DataFrame(populations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f03a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c130731",
   "metadata": {},
   "source": [
    "You can transpose the DataFrame (swap rows and columns) with similar syntax to a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a2bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0257df",
   "metadata": {},
   "source": [
    "Dictionaries of Series are treated in much the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a0a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = {\"Ohio\": frame3[\"Ohio\"][:-1],\"Nevada\": frame3[\"Nevada\"][:2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c89125",
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = {\"Ohio\": {2000: 1.5, 2001: 1.7},\"Nevada\": {2001: 2.4, 2002: 2.9}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed1ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3[\"Ohio\"][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd69bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3[\"Nevada\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f5d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d2393c",
   "metadata": {},
   "source": [
    "If a DataFrame’s index and columns have their name attributes set, these will also be displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e093d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3.index.name = \"year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd949b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3.columns.name = \"state\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb65592",
   "metadata": {},
   "source": [
    "Unlike Series, DataFrame does not have a name attribute. DataFrame's to_numpy method returns the data contained in the DataFrame as a two-dimensional ndarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e2b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39946d84",
   "metadata": {},
   "source": [
    "If the DataFrame’s columns are different data types, the data type of the returned array will be chosen to accommodate all of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2674fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3395ca0",
   "metadata": {},
   "source": [
    "#### Index Objects\n",
    "pandas’s Index objects are responsible for holding the axis labels (including a DataFrame's column names) and other metadata (like the axis name or names). Any array or other sequence of labels you use when constructing a Series or DataFrame is internally converted to an Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b099c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(3), index=[\"a\", \"b\", \"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde57f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = obj.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75f6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "index[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c05f7c5",
   "metadata": {},
   "source": [
    "Index objects are immutable and thus can’t be modified by the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index[1] = \"d\"  # TypeError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c6b458",
   "metadata": {},
   "source": [
    "Immutability makes it safer to share Index objects among data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c2e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.Index(np.arange(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf898bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 = pd.Series([1.5, -2.5, 0], index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c25285",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.index is labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41be637",
   "metadata": {},
   "source": [
    "Unlike Python sets, a pandas Index can contain duplicate labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00846baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Index([\"ffo\", \"ffo\", \"bar\", \"bar\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9bcfa9",
   "metadata": {},
   "source": [
    "Selections with duplicate labels will select all occurrences of that label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.Series([1,2,3,4], index=[\"foo\", \"foo\", \"bar\", \"bar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141bd29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['foo']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3951f8",
   "metadata": {},
   "source": [
    "#### Some Index methods and properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca38f789",
   "metadata": {},
   "source": [
    "| Method / Property | Description                                                                               |\n",
    "| ----------------- | ----------------------------------------------------------------------------------------- |\n",
    "| `append()`        | Concatenate with additional Index objects, producing a new Index                          |\n",
    "| `difference()`    | Compute set difference as an Index                                                        |\n",
    "| `intersection()`  | Compute set intersection                                                                  |\n",
    "| `union()`         | Compute set union                                                                         |\n",
    "| `isin()`          | Compute Boolean array indicating whether each value is contained in the passed collection |\n",
    "| `delete()`        | Compute new Index with element at index *i* deleted                                       |\n",
    "| `drop()`          | Compute new Index by deleting passed values                                               |\n",
    "| `insert()`        | Compute new Index by inserting element at index *i*                                       |\n",
    "| `is_monotonic`    | Returns `True` if each element is greater than or equal to the previous element           |\n",
    "| `is_unique`       | Returns `True` if the Index has no duplicate values                                       |\n",
    "| `unique()`        | Compute the array of unique values in the Index                                           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c4d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cf6f70b",
   "metadata": {},
   "source": [
    "### Essential Functionality\n",
    "This section will walk you through the fundamental mechanics of interacting with the data contained in a Series or DataFrame. In the chapters to come, we will delve more deeply into data analysis and manipulation topics using pandas. This book is not intended to serve as exhaustive documentation for the pandas library; instead, we'll focus on familiarizing you with heavily used features, leaving the less common (i.e., more esoteric) things for you to learn more about by reading the online pandas documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90aba0d",
   "metadata": {},
   "source": [
    "#### Reindexing\n",
    "An important method on pandas objects is reindex, which means to create a new object with the values rearranged to align with the new index. Consider an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([4.5, 7.2, -5.3, 3.6], index=[\"d\", \"b\", \"a\", \"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f39d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bed99e",
   "metadata": {},
   "source": [
    "Calling reindex on this Series rearranges the data according to the new index, introducing missing values if any index values were not already present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 = obj.reindex([\"a\", \"b\", \"c\", \"d\", \"e\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae58569",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5ef4f",
   "metadata": {},
   "source": [
    "For ordered data like time series, you may want to do some interpolation or filling of values when reindexing. The method option allows us to do this, using a method such as ffill, which forward-fills the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed87280",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj3 = pd.Series([\"blue\", \"purple\", \"yellow\"], index=[0, 2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj3.reindex(np.arange(6), method=\"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e434761",
   "metadata": {},
   "source": [
    "With DataFrame, reindex can alter the (row) index, columns, or both. When passed only a sequence, it reindexes the rows in the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed3363",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.arange(9).reshape((3, 3)), index=[\"a\", \"c\", \"d\"], columns=[\"Ohio\", \"Texas\", \"California\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2 = frame.reindex(index=[\"a\", \"b\", \"c\", \"d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc67573",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b8be98",
   "metadata": {},
   "source": [
    "The columns can be reindexed with the columns keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003cb265",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"Texas\", \"Utah\", \"California\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461dc0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.reindex(columns=states, fill_value=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f177a",
   "metadata": {},
   "source": [
    "Because \"Ohio\" was not in states, the data for that column is dropped from the result.\n",
    "\n",
    "Another way to reindex a particular axis is to pass the new axis labels as a positional argument and then specify the axis to reindex with the axis keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617cc27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.reindex(states, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec76d1ad",
   "metadata": {},
   "source": [
    "#### `reindex` function arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde2641",
   "metadata": {},
   "source": [
    "| Argument     | Description                                                                                                                                                          |\n",
    "| ------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `labels`     | New sequence to use as an index. Can be an Index instance or any other sequence-like Python data structure. An Index will be used exactly as-is without any copying. |\n",
    "| `index`      | Use the passed sequence as the new row-index labels.                                                                                                                 |\n",
    "| `columns`    | Use the passed sequence as the new column labels.                                                                                                                    |\n",
    "| `axis`       | Axis to reindex: `\"index\"` (rows, default) or `\"columns\"`. You can also call `reindex(index=...)` or `reindex(columns=...)` directly.                                |\n",
    "| `method`     | Interpolation (fill) method: `\"ffill\"` (forward-fill) or `\"bfill\"` (backward-fill).                                                                                  |\n",
    "| `fill_value` | Scalar value to insert for missing labels (default = NaN).                                                                                                           |\n",
    "| `limit`      | Max number of consecutive missing elements to fill when using `method`.                                                                                              |\n",
    "| `tolerance`  | Max absolute numeric distance allowed for inexact matches when using `method`.                                                                                       |\n",
    "| `level`      | Level of MultiIndex to match on (or subset).                                                                                                                         |\n",
    "| `copy`       | If `True`, always copy underlying data even when the new index equals the old one; if `False`, avoid copying when possible.                                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6474a894",
   "metadata": {},
   "source": [
    "#### Dropping Entries from an Axis\n",
    "Dropping one or more entries from an axis is simple if you already have an index array or list without those entries, since you can use the reindex method or .loc-based indexing. As that can require a bit of munging and set logic, the drop method will return a new object with the indicated value or values deleted from an axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008969c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(5.), index=[\"a\", \"b\", \"c\", \"d\", \"e\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cecc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864e6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obj = obj.drop(\"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd30e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.drop([\"d\", \"c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d498363b",
   "metadata": {},
   "source": [
    "With DataFrame, index values can be deleted from either axis. To illustrate this, we first create an example DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54396ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(16).reshape((4, 4)),index=[\"Ohio\", \"Colorado\", \"Utah\", \"New York\"], columns=[\"one\", \"two\", \"three\", \"four\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9467497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e6c101",
   "metadata": {},
   "source": [
    "Calling drop with a sequence of labels will drop values from the row labels (axis 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99666857",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(index=[\"Colorado\", \"Ohio\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b35b426",
   "metadata": {},
   "source": [
    "To drop labels from the columns, instead use the columns keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = data.drop(columns=[\"two\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77790b",
   "metadata": {},
   "source": [
    "You can also drop values from the columns by passing axis=1 (which is like NumPy) or axis=\"columns\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"two\" , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe2f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"two\", \"four\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550e093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3026cfe",
   "metadata": {},
   "source": [
    "#### Indexing, Selection, and Filtering\n",
    "Series indexing (obj[...]) works analogously to NumPy array indexing, except you can use the Series’s index values instead of only integers. Here are some examples of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c33da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(4.), index=[\"a\", \"b\", \"c\", \"d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a082ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aeb898",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[[\"b\", \"a\", \"d\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf714409",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[[1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[obj < 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5da84b",
   "metadata": {},
   "source": [
    "While you can select data by label this way, the preferred way to select index values is with the special `loc` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419415fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.loc[[\"b\", \"a\", \"d\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37feca37",
   "metadata": {},
   "source": [
    "The reason to prefer loc is because of the different treatment of integers when indexing with []. Regular []-based indexing will treat integers as labels if the index contains integers, so the behavior differs depending on the data type of the index. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf75161",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1 = pd.Series([1, 2, 3], index=[2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e589f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e60d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf70c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1[[0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d723aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[[0, 1, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd1a3ac",
   "metadata": {},
   "source": [
    "When using `loc`, the expression `obj.loc[[0, 1, 2]]` will fail when the index does not contain integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92228765",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.loc[[0, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dde5e0",
   "metadata": {},
   "source": [
    "Since loc operator indexes exclusively with labels, there is also an iloc operator that indexes exclusively with integers to work consistently whether or not the index contains integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e32da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1.iloc[[0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed06be",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.iloc[[0, 1, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8c6158",
   "metadata": {},
   "source": [
    "You can also slice with labels, but it works differently from normal Python slicing in that the endpoint is inclusive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee89bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.loc[\"a\":\"c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc8f4e9",
   "metadata": {},
   "source": [
    "Assigning values using these methods modifies the corresponding section of the Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2476fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.loc[\"b\":\"c\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300e68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed9808",
   "metadata": {},
   "source": [
    "Indexing into a DataFrame retrieves one or more columns either with a single value or sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c8f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(16).reshape((4, 4)), index=[\"Ohio\", \"Colorado\", \"Utah\", \"New York\"], columns=[\"one\", \"two\", \"three\", \"four\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491483ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf829c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['one']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da04f91",
   "metadata": {},
   "source": [
    "Indexing like this has a few special cases. The first is slicing or selecting data with a Boolean array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"three\"] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692241ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84652a93",
   "metadata": {},
   "source": [
    "The row selection syntax data[:2] is provided as a convenience. Passing a single element or a list to the [] operator selects columns.\n",
    "\n",
    "Another use case is indexing with a Boolean DataFrame, such as one produced by a scalar comparison. Consider a DataFrame with all Boolean values produced by comparing with a scalar value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4293c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdf4bf1",
   "metadata": {},
   "source": [
    "We can use this DataFrame to assign the value 0 to each location with the value True, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data < 5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2622c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['four'][data['four'] == 15] = 10\n",
    "\n",
    "data.loc[\"New York\", \"four\"] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661cdf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c5d29",
   "metadata": {},
   "source": [
    "Selection on DataFrame with loc and iloc\n",
    "\n",
    "Like Series, DataFrame has special attributes loc and iloc for label-based and integer-based indexing, respectively. Since DataFrame is two-dimensional, you can select a subset of the rows and columns \n",
    "\n",
    "with NumPy-like notation using either axis labels (loc) or integers (iloc).\n",
    "\n",
    "As a first example, let's select a single row by label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2debe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\"Colorado\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36164b4",
   "metadata": {},
   "source": [
    "The result of selecting a single row is a Series with an index that contains the DataFrame's column labels. To select multiple roles, creating a new DataFrame, pass a sequence of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077779db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[[\"Colorado\", \"New York\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\"Ohio\":\"Utah\", \"one\":\"three\"] #selecting rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce12e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\"Ohio\":\"Utah\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81810e99",
   "metadata": {},
   "source": [
    "You can combine both row and column selection in loc by separating the selections with a comma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e26d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\"Colorado\", [\"two\", \"three\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08699b71",
   "metadata": {},
   "source": [
    "We'll then perform some similar selections with integers using iloc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cfcb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2, [3, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed04db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[[1,2], [3, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1:2, [3, 0, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e8a7d1",
   "metadata": {},
   "source": [
    "Boolean arrays can be used with loc but not iloc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a28eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.three >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49aadfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.three >= 2, 'one']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310d360",
   "metadata": {},
   "source": [
    "Indexing options with DataFrame\n",
    "| Type | Notes |\n",
    "|------|-------|\n",
    "| `df[column]` | Select single column or sequence of columns from the DataFrame; special-case conveniences: Boolean array (filter rows), slice (slice rows), or Boolean DataFrame (set values based on some criterion) |\n",
    "| `df.loc[rows]` | Select single row or subset of rows from the DataFrame by **label** |\n",
    "| `df.loc[:, cols]` | Select single column or subset of columns by **label** |\n",
    "| `df.loc[rows, cols]` | Select both row(s) and column(s) by **label** |\n",
    "| `df.iloc[rows]` | Select single row or subset of rows from the DataFrame by **integer position** |\n",
    "| `df.iloc[:, cols]` | Select single column or subset of columns by **integer position** |\n",
    "| `df.iloc[rows, cols]` | Select both row(s) and column(s) by **integer position** |\n",
    "| `df.at[row, col]` | Select a **single scalar value** by row and column **label** |\n",
    "| `df.iat[row, col]` | Select a **single scalar value** by row and column **position** (integers) |\n",
    "| `reindex` method | Select either rows or columns by **labels** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f30e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32518488",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.iat[1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e3c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.four   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6213670",
   "metadata": {},
   "source": [
    "### Arithmetic and Data Alignment\n",
    "pandas can make it much simpler to work with objects that have different indexes. For example, when you add objects, if any index pairs are not the same, the respective index in the result will be the union of the index pairs. Let’s look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d1c1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=[\"a\", \"c\", \"d\", \"e\"])\n",
    "s2 = pd.Series([-2.1, 3.6, -1.5, 4, 3.1], index=[\"a\", \"c\", \"e\", \"f\", \"g\"])\n",
    "s1 + s2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdf8edd",
   "metadata": {},
   "source": [
    "The internal data alignment introduces missing values in the label locations that don’t overlap. Missing values will then propagate in further arithmetic computations.\n",
    "\n",
    "In the case of DataFrame, alignment is performed on both rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8894f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(9.).reshape((3, 3)), columns=list(\"bcd\"), index=[\"Ohio\", \"Texas\", \"Colorado\"])\n",
    "df2 = pd.DataFrame(np.arange(12.).reshape((4, 3)), columns=list(\"bde\"), index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff9b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af39737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 + df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d10beac",
   "metadata": {},
   "source": [
    "Using the add method on df1, I pass df2 and an argument to fill_value, which substitutes the passed value for any missing values in the operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a214179",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(12.).reshape((3, 4)),columns=list(\"abcd\"))\n",
    "df2 = pd.DataFrame(np.arange(20.).reshape((4, 5)),columns=list(\"abcde\"))\n",
    "\n",
    "df2.loc[1, 'b'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4171879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7c8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 + df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507dd94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.add(df2, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6672f5c8",
   "metadata": {},
   "source": [
    "Flexible arithmetic methods\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `add`, `radd` | Methods for addition (`+`) |\n",
    "| `sub`, `rsub` | Methods for subtraction (`-`) |\n",
    "| `div`, `rdiv` | Methods for division (`/`) |\n",
    "| `floordiv`, `rfloordiv` | Methods for floor division (`//`) |\n",
    "| `mul`, `rmul` | Methods for multiplication (`*`) |\n",
    "| `pow`, `rpow` | Methods for exponentiation (`**`) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc31dd",
   "metadata": {},
   "source": [
    "### Function Application and Mapping\n",
    "NumPy ufuncs (element-wise array methods) also work with pandas objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "25a8e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.random.standard_normal((4, 3)), columns=list(\"bde\"), index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4cb8d462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>0.088197</td>\n",
       "      <td>0.767472</td>\n",
       "      <td>0.581320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>-0.683308</td>\n",
       "      <td>-2.000710</td>\n",
       "      <td>0.575624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>-0.319300</td>\n",
       "      <td>-0.089491</td>\n",
       "      <td>0.102543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>0.388269</td>\n",
       "      <td>-1.734548</td>\n",
       "      <td>0.965957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               b         d         e\n",
       "Utah    0.088197  0.767472  0.581320\n",
       "Ohio   -0.683308 -2.000710  0.575624\n",
       "Texas  -0.319300 -0.089491  0.102543\n",
       "Oregon  0.388269 -1.734548  0.965957"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2cbf5bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>0.088197</td>\n",
       "      <td>0.767472</td>\n",
       "      <td>0.581320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>0.683308</td>\n",
       "      <td>2.000710</td>\n",
       "      <td>0.575624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>0.319300</td>\n",
       "      <td>0.089491</td>\n",
       "      <td>0.102543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>0.388269</td>\n",
       "      <td>1.734548</td>\n",
       "      <td>0.965957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               b         d         e\n",
       "Utah    0.088197  0.767472  0.581320\n",
       "Ohio    0.683308  2.000710  0.575624\n",
       "Texas   0.319300  0.089491  0.102543\n",
       "Oregon  0.388269  1.734548  0.965957"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e770cc3",
   "metadata": {},
   "source": [
    "Another frequent operation is applying a function on one-dimensional arrays to each column or row. DataFrame’s apply method does exactly this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7a6aedf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    1.071578\n",
       "d    2.768181\n",
       "e    0.863414\n",
       "dtype: float64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "frame.apply(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4b95747f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.071577519626428)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(frame['b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0065d2ed",
   "metadata": {},
   "source": [
    "Here the function f, which computes the difference between the maximum and minimum of a Series, is invoked once on each column in frame. The result is a Series having the columns of frame as its index.\n",
    "\n",
    "If you pass axis=\"columns\" to apply, the function will be invoked once per row instead. A helpful way to think about this is as \"apply across the columns\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b4a137b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Utah      0.679274\n",
       "Ohio      2.576334\n",
       "Texas     0.421843\n",
       "Oregon    2.700506\n",
       "dtype: float64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.apply(f1, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eef496f",
   "metadata": {},
   "source": [
    "Many of the most common array statistics (like sum and mean) are DataFrame methods, so using apply is not necessary.\n",
    "\n",
    "The function passed to apply need not return a scalar value; it can also return a Series with multiple values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b53eaf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.683308</td>\n",
       "      <td>-2.000710</td>\n",
       "      <td>0.102543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.388269</td>\n",
       "      <td>0.767472</td>\n",
       "      <td>0.965957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            b         d         e\n",
       "min -0.683308 -2.000710  0.102543\n",
       "max  0.388269  0.767472  0.965957"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f2(x):\n",
    "    return pd.Series([x.min(), x.max()], index=[\"min\", \"max\"])\n",
    "\n",
    "frame.apply(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00617339",
   "metadata": {},
   "source": [
    "Element-wise Python functions can be used, too. Suppose you wanted to compute a formatted string from each floating-point value in frame. You can do this with applymap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "945b1525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>-0.68</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>0.39</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            b      d     e\n",
       "Utah     0.09   0.77  0.58\n",
       "Ohio    -0.68  -2.00  0.58\n",
       "Texas   -0.32  -0.09  0.10\n",
       "Oregon   0.39  -1.73  0.97"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_format(x):\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "frame.map(my_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1017d179",
   "metadata": {},
   "source": [
    "The reason for the name applymap is that Series has a map method for applying an element-wise function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "be565986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>0.088197</td>\n",
       "      <td>0.767472</td>\n",
       "      <td>0.581320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>-0.683308</td>\n",
       "      <td>-2.000710</td>\n",
       "      <td>0.575624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>-0.319300</td>\n",
       "      <td>-0.089491</td>\n",
       "      <td>0.102543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>0.388269</td>\n",
       "      <td>-1.734548</td>\n",
       "      <td>0.965957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               b         d         e\n",
       "Utah    0.088197  0.767472  0.581320\n",
       "Ohio   -0.683308 -2.000710  0.575624\n",
       "Texas  -0.319300 -0.089491  0.102543\n",
       "Oregon  0.388269 -1.734548  0.965957"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "48833aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Utah      0.58\n",
       "Ohio      0.58\n",
       "Texas     0.10\n",
       "Oregon    0.97\n",
       "Name: e, dtype: object"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[\"e\"].map(my_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d39a48",
   "metadata": {},
   "source": [
    "### Sorting and Ranking\n",
    "Sorting a dataset by some criterion is another important built-in operation. To sort lexicographically by row or column label, use the sort_index method, which returns a new, sorted object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48645a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(4), index=[\"d\", \"a\", \"b\", \"c\"])\n",
    "obj.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e2f6d",
   "metadata": {},
   "source": [
    "With a DataFrame, you can sort by index on either axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.arange(8).reshape((2, 4)), index=[\"three\", \"one\"], columns=[\"d\", \"a\", \"b\", \"c\"])\n",
    "frame.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be491ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sort_index(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9d8817",
   "metadata": {},
   "source": [
    "The data is sorted in ascending order by default but can be sorted in descending order, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8433ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sort_index(axis=\"columns\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b052dc",
   "metadata": {},
   "source": [
    "To sort a Series by its values, use its sort_values method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613462f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([4, 7, -3, 2])\n",
    "\n",
    "obj.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f5b61d",
   "metadata": {},
   "source": [
    "Any missing values are sorted to the end of the Series by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ed498",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([4, np.nan, 7, np.nan, -3, 2])\n",
    "obj.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2bc8a3",
   "metadata": {},
   "source": [
    "Missing values can be sorted to the start instead by using the na_position option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbdfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.sort_values(na_position=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8990fbd6",
   "metadata": {},
   "source": [
    "When sorting a DataFrame, you can use the data in one or more columns as the sort keys. To do so, pass one or more column names to sort_values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a2e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({\"b\": [4, 7, -3, 2], \"a\": [0, 1, 0, 1]})\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1ef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sort_values(\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b16c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sort_values([\"a\", \"b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf1daca",
   "metadata": {},
   "source": [
    "Ranking assigns ranks from one through the number of valid data points in an array, starting from the lowest value. The rank methods for Series and DataFrame are the place to look; by default, rank breaks ties by assigning each group the mean rank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595d9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([7, -5, 7, 4, 2, 0, 4])  #[-5, 0, 2, 4,4,7,7]\n",
    "obj.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8c54b5",
   "metadata": {},
   "source": [
    "Ranks can also be assigned according to the order in which they’re observed in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.rank(method=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92550c97",
   "metadata": {},
   "source": [
    "Here, instead of using the average rank 6.5 for the entries 0 and 2, they instead have been set to 6 and 7 because label 0 precedes label 2 in the data.\n",
    "\n",
    "You can rank in descending order, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed789bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.rank(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d47ab7",
   "metadata": {},
   "source": [
    "DataFrame can compute ranks over the rows or the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11857421",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({\"b\": [4.3, 7, -3, 2], \"a\": [0, 1, 0, 1], \"c\": [-2, 5, 8, -2.5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf5892cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>a</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     b    a    c\n",
       "0  3.0  2.0  1.0\n",
       "1  3.0  1.0  2.0\n",
       "2  1.0  2.0  3.0\n",
       "3  3.0  2.0  1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.rank(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e0e80c",
   "metadata": {},
   "source": [
    " Tie-breaking methods with rank\n",
    " | Method | Description |\n",
    "|--------|------------- |\n",
    "| `\"average\"` | Default: assign the **average rank** to each entry in the equal group |\n",
    "| `\"min\"` | Use the **minimum rank** for the whole group |\n",
    "| `\"max\"` | Use the **maximum rank** for the whole group |\n",
    "| `\"first\"` | Assign ranks in the **order the values appear** in the data |\n",
    "| `\"dense\"` | Like `\"min\"`, but ranks **always increase by 1** between groups (no gaps) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554eb1b4",
   "metadata": {},
   "source": [
    "### Axis Indexes with Duplicate Labels\n",
    "Up until now almost all of the examples we have looked at have unique axis labels (index values). While many pandas functions (like reindex) require that the labels be unique, it’s not mandatory. Let’s consider a small Series with duplicate indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8124ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(5), index=[\"a\", \"a\", \"b\", \"b\", \"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987d1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1759b58",
   "metadata": {},
   "source": [
    "The `is_unique` property of the index can tell you whether or not its labels are unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d55f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b59e653",
   "metadata": {},
   "source": [
    "Data selection is one of the main things that behaves differently with duplicates. Indexing a label with multiple entries returns a Series, while single entries return a scalar value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca2b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[\"a\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c16191",
   "metadata": {},
   "source": [
    "This can make your code more complicated, as the output type from indexing can vary based on whether or not a label is repeated.\n",
    "\n",
    "The same logic extends to indexing rows (or columns) in a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fc1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.standard_normal((5, 3)), index=[\"a\", \"a\", \"b\", \"b\", \"c\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457021c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb82192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61403481",
   "metadata": {},
   "source": [
    "## Summarizing and Computing Descriptive Statistics\n",
    "pandas objects are equipped with a set of common mathematical and statistical methods. Most of these fall into the category of reductions or summary statistics, methods that extract a single value (like the sum or mean) from a Series, or a Series of values from the rows or columns of a DataFrame. Compared with the similar methods found on NumPy arrays, they have built-in handling for missing data. Consider a small DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12817cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5], [np.nan, np.nan], [0.75, -1.3]], index=[\"a\", \"b\", \"c\", \"d\"], columns=[\"one\", \"two\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58aee0a",
   "metadata": {},
   "source": [
    "Calling DataFrame’s `sum` method returns a Series containing column sums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539857ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f444fa",
   "metadata": {},
   "source": [
    "Passing `axis=\"columns\"` or `axis=1` sums across the columns instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b56e82",
   "metadata": {},
   "source": [
    "When an entire row or column contains all NA values, the sum is 0, whereas if any value is not NA, then the result is NA. This can be disabled with the `skipna` option, in which case any NA value in a row or column names the corresponding result NA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c051cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=\"index\", skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c92a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=\"columns\", skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff70da",
   "metadata": {},
   "source": [
    "Some aggregations, like mean, require at least one non-NA value to yield a value result, so here we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624c624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f58ecf",
   "metadata": {},
   "source": [
    "Some methods, like `idxmin` and `idxmax`, return indirect statistics, like the index value where the minimum or maximum values are attained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa8909",
   "metadata": {},
   "source": [
    "Other methods are accumulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16efadc",
   "metadata": {},
   "source": [
    "Some methods are neither reductions nor accumulations. describe is one such example, producing multiple summary statistics in one shot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd491bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd83e071",
   "metadata": {},
   "source": [
    "On nonnumeric data, describe produces alternative summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f08575",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([\"a\", \"a\", \"b\", \"c\"] * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e816bd67",
   "metadata": {},
   "source": [
    "Descriptive and summary statistics\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `count` | Number of non-NA values |\n",
    "| `describe` | Compute set of summary statistics |\n",
    "| `min`, `max` | Compute minimum and maximum values |\n",
    "| `argmin`, `argmax` | Compute index **locations** (integers) at which minimum or maximum value is obtained, respectively; not available on DataFrame objects |\n",
    "| `idxmin`, `idxmax` | Compute index **labels** at which minimum or maximum value is obtained, respectively |\n",
    "| `quantile` | Compute sample quantile ranging from 0 to 1 (default: 0.5) |\n",
    "| `sum` | Sum of values |\n",
    "| `mean` | Mean of values |\n",
    "| `median` | Arithmetic median (50 % quantile) of values |\n",
    "| `mad` | Mean absolute deviation from mean value |\n",
    "| `prod` | Product of all values |\n",
    "| `var` | Sample variance of values |\n",
    "| `std` | Sample standard deviation of values |\n",
    "| `skew` | Sample skewness (third moment) of values |\n",
    "| `kurt` | Sample kurtosis (fourth moment) of values |\n",
    "| `cumsum` | Cumulative sum of values |\n",
    "| `cummin`, `cummax` | Cumulative minimum or maximum of values, respectively |\n",
    "| `cumprod` | Cumulative product of values |\n",
    "| `diff` | Compute first arithmetic difference (useful for time series) |\n",
    "| `pct_change` | Compute percent changes |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b322b4",
   "metadata": {},
   "source": [
    "## Correlation and Covariance\n",
    "Some summary statistics, like correlation and covariance, are computed from pairs of arguments. Let’s consider some DataFrames of stock prices and volumes originally obtained from Yahoo! Finance and available in binary Python pickle files you can find in the accompanying datasets for the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03becf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = pd.read_pickle(\"examples/yahoo_price.pkl\")\n",
    "volume = pd.read_pickle(\"examples/yahoo_volume.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a4ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = price.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9857597b",
   "metadata": {},
   "source": [
    "The `corr` method of Series computes the correlation of the overlapping, non-NA, aligned-by-index values in two Series. Relatedly, `cov` computes the covariance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f116e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns[\"MSFT\"].corr(returns[\"IBM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d8a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns[\"MSFT\"].cov(returns[\"IBM\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a732ce",
   "metadata": {},
   "source": [
    "DataFrame’s `corr` and `cov` methods, on the other hand, return a full correlation or covariance matrix as a DataFrame, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04992f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ade9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fdb48c",
   "metadata": {},
   "source": [
    "Using DataFrame’s corrwith method, you can compute pair-wise correlations between a DataFrame’s columns or rows with another Series or DataFrame. Passing a Series returns a Series with the correlation value computed for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.corrwith(returns[\"IBM\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad020f",
   "metadata": {},
   "source": [
    "Passing a DataFrame computes the correlations of matching column names. Here, I compute correlations of percent changes with volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.corrwith(volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caecfcb",
   "metadata": {},
   "source": [
    "## Unique Values, Value Counts, and Membership\n",
    "Another class of related methods extracts information about the values contained in a one-dimensional Series. To illustrate these, consider this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba89708",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([\"c\", \"a\", \"d\", \"a\", \"a\", \"b\", \"b\", \"c\", \"c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c926b8",
   "metadata": {},
   "source": [
    "The first function is unique, which gives you an array of the unique values in a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ecab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = obj.unique()\n",
    "\n",
    "print(uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a49b8a",
   "metadata": {},
   "source": [
    "The unique values are not necessarily returned in the order in which they first appear, and not in sorted order, but they could be sorted after the fact if needed `(uniques.sort())`. Relatedly, `value_counts` computes a Series containing value frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ae3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488403f0",
   "metadata": {},
   "source": [
    "The Series is sorted by value in descending order as a convenience. `value_counts` is also available as a top-level pandas method that can be used with NumPy arrays or other Python sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(obj.to_numpy(), sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52930b59",
   "metadata": {},
   "source": [
    "`isin` performs a vectorized set membership check and can be useful in filtering a dataset down to a subset of values in a Series or column in a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81aaa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e345f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = obj.isin([\"b\", \"c\"])\n",
    "\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffee8b7",
   "metadata": {},
   "source": [
    "Related to isin is the Index.get_indexer method, which gives you an index array from an array of possibly nondistinct values into another array of distinct values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_match = pd.Series([\"c\", \"a\", \"b\", \"b\", \"c\", \"a\"])\n",
    "\n",
    "unique_vals = pd.Series([\"c\", \"b\", \"a\"])\n",
    "\n",
    "# get the indices of the unique values in the to_match series like binding new index to the to_match series\n",
    "indices = pd.Index(unique_vals).get_indexer(to_match)\n",
    "to_match.reindex(indices)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7520b9",
   "metadata": {},
   "source": [
    "### Unique, value counts, and set membership methods\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `isin` | Compute a Boolean array indicating whether each Series or DataFrame value is contained in the passed sequence of values |\n",
    "| `get_indexer` | Compute integer indices for each value in an array into another array of distinct values; helpful for data alignment and join-type operations |\n",
    "| `unique` | Compute an array of unique values in a Series, returned in the order observed |\n",
    "| `value_counts` | Return a Series containing unique values as its index and frequencies as its values, ordered count in descending order |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f151660c",
   "metadata": {},
   "source": [
    "In some cases, you may want to compute a histogram on multiple related columns in a DataFrame. Here’s an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Qu1\": [1, 3, 4, 3, 4], \"Qu2\": [2, 3, 1, 2, 3], \"Qu3\": [1, 5, 2, 4, 4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de30fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0937b1e",
   "metadata": {},
   "source": [
    "We can compute the value counts for a single column, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Qu1\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be04b00",
   "metadata": {},
   "source": [
    "To compute this for all columns, pass pandas.value_counts to the DataFrame’s apply method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87dc0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data.apply(pd.value_counts).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035801f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d99bce9",
   "metadata": {},
   "source": [
    "Here, the row labels in the result are the distinct values occurring in all of the columns. The values are the respective counts of these values in each column.\n",
    "\n",
    "There is also a DataFrame.value_counts method, but it computes counts considering each row of the DataFrame as a tuple to determine the number of occurrences of each distinct row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7df1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"a\": [1, 1, 1, 2, 2], \"b\": [0, 0, 1, 0, 0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa864b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716d18a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea524db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05457ebb",
   "metadata": {},
   "source": [
    "## Data Loading, Storage, and File Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d318be",
   "metadata": {},
   "source": [
    "Reading data and making it accessible (often called data loading) is a necessary first step for using most of the tools in this book. The term parsing is also sometimes used to describe loading text data and interpreting it as tables and different data types. I’m going to focus on data input and output using pandas, though there are numerous tools in other libraries to help with reading and writing data in various formats.\n",
    "\n",
    "Input and output typically fall into a few main categories: reading text files and other more efficient on-disk formats, loading data from databases, and interacting with network sources like web APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b03855",
   "metadata": {},
   "source": [
    "#### Reading and Writing Data in Text Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d78e0",
   "metadata": {},
   "source": [
    "pandas features a number of functions for reading tabular data as a DataFrame object. Table below summarizes some of them; pandas.read_csv is one of the most frequently used in this book. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e816a52",
   "metadata": {},
   "source": [
    "### Text and binary data loading functions in pandas\n",
    "| Function | Description |\n",
    "|----------|-------------|\n",
    "| `read_csv` | Load delimited data from a file, URL, or file-like object; uses comma as default delimiter |\n",
    "| `read_fwf` | Read data in fixed-width column format (i.e., no delimiters) |\n",
    "| `read_clipboard` | Variation of `read_csv` that reads data from the clipboard; useful for converting tables from web pages |\n",
    "| `read_excel` | Read tabular data from an Excel `.xls` or `.xlsx` file |\n",
    "| `read_hdf` | Read HDF5 files written by pandas |\n",
    "| `read_html` | Read all tables found in the given HTML document |\n",
    "| `read_json` | Read data from a JSON (JavaScript Object Notation) string, file, URL, or file-like object |\n",
    "| `read_feather` | Read the Feather binary file format |\n",
    "| `read_orc` | Read the Apache ORC binary file format |\n",
    "| `read_parquet` | Read the Apache Parquet binary file format |\n",
    "| `read_pickle` | Read an object stored by pandas using the Python pickle format |\n",
    "| `read_sas` | Read a SAS dataset stored in one of the SAS system’s custom storage formats |\n",
    "| `read_spss` | Read a data file created by SPSS |\n",
    "| `read_sql` | Read the results of a SQL query (via SQLAlchemy) |\n",
    "| `read_sql_table` | Read an entire SQL table (via SQLAlchemy); equivalent to `SELECT * FROM table` with `read_sql` |\n",
    "| `read_stata` | Read a dataset from Stata file format |\n",
    "| `read_xml` | Read a table of data from an XML file |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550b1584",
   "metadata": {},
   "source": [
    "#### Indexing\n",
    "Can treat one or more columns as the returned DataFrame, and whether to get column names from the file, arguments you provide, or not at all.\n",
    "\n",
    "#### Type inference and data conversion\n",
    "Includes the user-defined value conversions and custom list of missing value markers.\n",
    "\n",
    "#### Date and time parsing\n",
    "Includes a combining capability, including combining date and time information spread over multiple columns into a single column in the result.\n",
    "\n",
    "#### Iterating\n",
    "Support for iterating over chunks of very large files.\n",
    "\n",
    "#### Unclean data issues\n",
    "Includes skipping rows or a footer, comments, or other minor things like numeric data with thousands separated by commas.\n",
    "\n",
    "Because of how messy data in the real world can be, some of the data loading functions (especially `pandas.read_csv`) have accumulated a long list of optional arguments over time. It's normal to feel overwhelmed by the number of different parameters (`pandas.read_csv` has around 50). The online pandas documentation has many examples about how each of these works, so if you're struggling to read a particular file, there might be a similar enough example to help you find the right parameters.\n",
    "\n",
    "Some of these functions perform type inference, because the column data types are not part of the data format. That means you don’t necessarily have to specify which columns are numeric, integer, Boolean, or string. Other data formats, like HDF5, ORC, and Parquet, have the data type information embedded in the format.\n",
    "\n",
    "Handling dates and other custom types can require extra effort.\n",
    "\n",
    "Let’s start with a small comma-separated values (CSV) text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "82200ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"examples/ex1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42bbfb1",
   "metadata": {},
   "source": [
    "A file will not always have a header row. Consider this file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6d255",
   "metadata": {},
   "source": [
    "To read this file, you have a couple of options. You can allow pandas to assign default column names, or you can specify names yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "061659d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3      4\n",
       "0  1   2   3   4  hello\n",
       "1  5   6   7   8  world\n",
       "2  9  10  11  12    foo"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"examples/ex2.csv\", header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6b54c3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"examples/ex2.csv\", names=[\"a\", \"b\", \"c\", \"d\", \"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8fa9c9",
   "metadata": {},
   "source": [
    "Suppose you wanted the message column to be the index of the returned DataFrame. You can either indicate you want the column at index 4 or named \"message\" using the index_col argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "43226fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hello</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foo</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         a   b   c   d\n",
       "message               \n",
       "hello    1   2   3   4\n",
       "world    5   6   7   8\n",
       "foo      9  10  11  12"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\"a\", \"b\", \"c\", \"d\", \"message\"]\n",
    "pd.read_csv(\"examples/ex2.csv\", names=names, index_col=\"message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e45bbd7",
   "metadata": {},
   "source": [
    "In some cases, a table might not have a fixed delimiter, using whitespace or some other pattern to separate fields. Consider a text file that looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fb116e",
   "metadata": {},
   "source": [
    "While you could do some munging by hand, the fields here are separated by a variable amount of whitespace. In these cases, you can pass a regular expression as a delimiter for pandas.read_csv. This can be expressed by the regular expression \\s+, so we have then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "dc398680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\IBRAHEEM\\AppData\\Local\\Temp\\ipykernel_18512\\1673285606.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  result = pd.read_csv(\"examples/ex3.txt\", sep=\"\\s+\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>-0.264438</td>\n",
       "      <td>-1.026059</td>\n",
       "      <td>-0.619500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbb</th>\n",
       "      <td>0.927272</td>\n",
       "      <td>0.302904</td>\n",
       "      <td>-0.032399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccc</th>\n",
       "      <td>-0.264273</td>\n",
       "      <td>-0.386314</td>\n",
       "      <td>-0.217601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddd</th>\n",
       "      <td>-0.871858</td>\n",
       "      <td>-0.348382</td>\n",
       "      <td>1.100491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         B         C\n",
       "aaa -0.264438 -1.026059 -0.619500\n",
       "bbb  0.927272  0.302904 -0.032399\n",
       "ccc -0.264273 -0.386314 -0.217601\n",
       "ddd -0.871858 -0.348382  1.100491"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv(\"examples/ex3.txt\", sep=\"\\s+\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef06bd69",
   "metadata": {},
   "source": [
    "Because there was one fewer column name than the number of data rows, pandas.read_csv infers that the first column should be the DataFrame’s index in this special case.\n",
    "\n",
    "The file parsing functions have many additional arguments to help you handle the wide variety of exception file formats that occur (see a partial listing in Table). For example, you can skip the first, third, and fourth rows of a file with skiprows:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "443b659f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# hey!\n",
    "a,b,c,d,message\n",
    "# just wanted to make things more difficult for you\n",
    "# who reads CSV files with computers, anyway?\n",
    "1,2,3,4,hello\n",
    "5,6,7,8,world\n",
    "9,10,11,12,foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c366c57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"examples/ex4.csv\", skiprows=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9506f8",
   "metadata": {},
   "source": [
    "Handling missing values is an important and frequently nuanced part of the file reading process. Missing data is usually either not present (empty string) or marked by some sentinel (placeholder) value. By default, pandas uses a set of commonly occurring sentinels, such as NA and NULL:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f177f49e",
   "metadata": {},
   "source": [
    "something,a,b,c,d,message\n",
    "one,1,2,3,4,NA\n",
    "two,5,6,,8,world\n",
    "three,9,10,11,12,foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7772efdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>something</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>three</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  something  a   b     c   d message\n",
       "0       one  1   2   3.0   4     NaN\n",
       "1       two  5   6   NaN   8   world\n",
       "2     three  9  10  11.0  12     foo"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv(\"examples/ex5.csv\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264a9cc1",
   "metadata": {},
   "source": [
    "Recall that pandas outputs missing values as NaN, so we have two null or missing values in result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "79803591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>something</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   something      a      b      c      d  message\n",
       "0      False  False  False  False  False     True\n",
       "1      False  False  False   True  False    False\n",
       "2      False  False  False  False  False    False"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e964aa94",
   "metadata": {},
   "source": [
    "The `na_values` option accepts a sequence of strings to add to the default list of strings recognized as missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce186d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>something</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>three</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  something  a   b     c   d message\n",
       "0       one  1   2   3.0   4     NaN\n",
       "1       two  5   6   NaN   8   world\n",
       "2     three  9  10  11.0  12     foo"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv(\"examples/ex5.csv\", na_values=[\"NULL\"])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ef6b89",
   "metadata": {},
   "source": [
    "`pandas.read_csv` has a list of many default NA value representations, but these defaults can be disabled with the `keep_default_na` option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "05137dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>something</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>three</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  something  a   b   c   d message\n",
       "0       one  1   2   3   4      NA\n",
       "1       two  5   6       8   world\n",
       "2     three  9  10  11  12     foo"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = pd.read_csv(\"examples/ex5.csv\", keep_default_na=False)\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3a0ad78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>something</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   something      a      b      c      d  message\n",
       "0      False  False  False  False  False    False\n",
       "1      False  False  False  False  False    False\n",
       "2      False  False  False  False  False    False"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fc89b68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>something</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>three</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  something  a   b   c   d message\n",
       "0       one  1   2   3   4     NaN\n",
       "1       two  5   6       8   world\n",
       "2     three  9  10  11  12     foo"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3 = pd.read_csv(\"examples/ex5.csv\", keep_default_na=False  , na_values=[\"NA\"])\n",
    "result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "58dd10cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>something</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   something      a      b      c      d  message\n",
       "0      False  False  False  False  False     True\n",
       "1      False  False  False  False  False    False\n",
       "2      False  False  False  False  False    False"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909312ee",
   "metadata": {},
   "source": [
    "Different NA sentinels can be specified for each column in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1d2d60d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>something</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>three</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  something  a   b   c   d message\n",
       "0       one  1   2   3   4     NaN\n",
       "1       NaN  5   6       8   world\n",
       "2     three  9  10  11  12     NaN"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentinels = {\"message\": [\"foo\", \"NA\"], \"something\": [\"two\"]}\n",
    "result4 = pd.read_csv(\"examples/ex5.csv\", keep_default_na=False, na_values=sentinels)\n",
    "result4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022f0b0",
   "metadata": {},
   "source": [
    "#### Some `pandas.read_csv` function arguments\n",
    "| Argument | Description |\n",
    "|----------|-------------|\n",
    "| `path` | String indicating filesystem location, URL, or file-like object. |\n",
    "| `sep` or `delimiter` | Character sequence or regular expression to split fields in each row. |\n",
    "| `header` | Row number to use as column names; defaults to 0 (first row). Use `None` if there is no header row. |\n",
    "| `index_col` | Column number(s) or name(s) to use as the row index; can be single or list for hierarchical index. |\n",
    "| `names` | List of column names to use for the result. |\n",
    "| `skiprows` | Number of rows to skip at start of file, or list of row numbers (0-based) to skip. |\n",
    "| `na_values` | Sequence of strings to treat as NA/NaN (added to default list unless `keep_default_na=False`). |\n",
    "| `keep_default_na` | Whether to use the default NA value list (`True` by default). |\n",
    "| `comment` | Character(s) to split comments off the end of lines. |\n",
    "| `parse_dates` | Attempt to parse data to datetime. `False` by default; can be `True`, list of columns, or list of lists/tuples for multi-column dates. |\n",
    "| `keep_date_col` | If joining columns to parse date, keep the joined columns (`False` by default). |\n",
    "| `converters` | Dict mapping column number/name to functions, e.g. `{\"foo\": f}` applies `f` to the \"foo\" column. |\n",
    "| `dayfirst` | Treat ambiguous dates as international format (e.g. 7/6/2012 → June 7, 2012); `False` by default. |\n",
    "| `date_parser` | Function to use to parse dates. |\n",
    "| `nrows` | Number of rows to read from beginning of file (excluding header). |\n",
    "| `iterator` | Return a `TextFileReader` for iterative/chunked reading; usable with `with` statement. |\n",
    "| `chunksize` | For iteration, number of rows per chunk. |\n",
    "| `skip_footer` | Number of lines to ignore at end of file. |\n",
    "| `verbose` | Print parsing info (timing, memory usage). |\n",
    "| `encoding` | Text encoding (e.g. `\"utf-8\"`); defaults to `\"utf-8\"` if `None`. |\n",
    "| `squeeze` | If parsed data contains only one column, return a `Series`. |\n",
    "| `thousands` | Thousands separator (e.g. `\",\"` or `\".\"`); default `None`. |\n",
    "| `decimal` | Decimal separator (e.g. `\".\"` or `\",\"`); default `\".\"`. |\n",
    "| `engine` | CSV parsing engine: `\"c\"` (default), `\"python\"`, or `\"pyarrow\"` (`\"pyarrow\"` faster on large files; `\"python\"` supports extra features but slower). |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8deac0",
   "metadata": {},
   "source": [
    "#### Reading Text Files in Pieces\n",
    "When processing very large files or figuring out the right set of arguments to correctly process a large file, you may want to read only a small piece of a file or iterate through smaller chunks of the file.\n",
    "\n",
    "Before we look at a large file, we make the pandas display settings more compact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "94552105",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4842aa",
   "metadata": {},
   "source": [
    "Now we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "499a05d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.467976</td>\n",
       "      <td>-0.038649</td>\n",
       "      <td>-0.295344</td>\n",
       "      <td>-1.824726</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.358893</td>\n",
       "      <td>1.404453</td>\n",
       "      <td>0.704965</td>\n",
       "      <td>-0.200638</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.501840</td>\n",
       "      <td>0.659254</td>\n",
       "      <td>-0.421691</td>\n",
       "      <td>-0.057688</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204886</td>\n",
       "      <td>1.074134</td>\n",
       "      <td>1.388361</td>\n",
       "      <td>-0.982404</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.354628</td>\n",
       "      <td>-0.133116</td>\n",
       "      <td>0.283763</td>\n",
       "      <td>-0.837063</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2.311896</td>\n",
       "      <td>-0.417070</td>\n",
       "      <td>-1.409599</td>\n",
       "      <td>-0.515821</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-0.479893</td>\n",
       "      <td>-0.650419</td>\n",
       "      <td>0.745152</td>\n",
       "      <td>-0.646038</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.523331</td>\n",
       "      <td>0.787112</td>\n",
       "      <td>0.486066</td>\n",
       "      <td>1.093156</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-0.362559</td>\n",
       "      <td>0.598894</td>\n",
       "      <td>-1.843201</td>\n",
       "      <td>0.887292</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-0.096376</td>\n",
       "      <td>-1.012999</td>\n",
       "      <td>-0.657431</td>\n",
       "      <td>-0.573315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           one       two     three      four key\n",
       "0     0.467976 -0.038649 -0.295344 -1.824726   L\n",
       "1    -0.358893  1.404453  0.704965 -0.200638   B\n",
       "2    -0.501840  0.659254 -0.421691 -0.057688   G\n",
       "3     0.204886  1.074134  1.388361 -0.982404   R\n",
       "4     0.354628 -0.133116  0.283763 -0.837063   Q\n",
       "...        ...       ...       ...       ...  ..\n",
       "9995  2.311896 -0.417070 -1.409599 -0.515821   L\n",
       "9996 -0.479893 -0.650419  0.745152 -0.646038   E\n",
       "9997  0.523331  0.787112  0.486066  1.093156   K\n",
       "9998 -0.362559  0.598894 -1.843201  0.887292   G\n",
       "9999 -0.096376 -1.012999 -0.657431 -0.573315   0\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv(\"examples/ex6.csv\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d1e13a",
   "metadata": {},
   "source": [
    "The elipsis marks `...` indicate that rows in the middle of the DataFrame have been omitted.\n",
    "\n",
    "If you want to read only a small number of rows (avoiding reading the entire file), specify that with `nrows`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "098d32a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.467976</td>\n",
       "      <td>-0.038649</td>\n",
       "      <td>-0.295344</td>\n",
       "      <td>-1.824726</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.358893</td>\n",
       "      <td>1.404453</td>\n",
       "      <td>0.704965</td>\n",
       "      <td>-0.200638</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.501840</td>\n",
       "      <td>0.659254</td>\n",
       "      <td>-0.421691</td>\n",
       "      <td>-0.057688</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204886</td>\n",
       "      <td>1.074134</td>\n",
       "      <td>1.388361</td>\n",
       "      <td>-0.982404</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.354628</td>\n",
       "      <td>-0.133116</td>\n",
       "      <td>0.283763</td>\n",
       "      <td>-0.837063</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.817480</td>\n",
       "      <td>0.742273</td>\n",
       "      <td>0.419395</td>\n",
       "      <td>-2.251035</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.776764</td>\n",
       "      <td>0.935518</td>\n",
       "      <td>-0.332872</td>\n",
       "      <td>-1.875641</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.913135</td>\n",
       "      <td>1.530624</td>\n",
       "      <td>-0.572657</td>\n",
       "      <td>0.477252</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.358480</td>\n",
       "      <td>-0.497572</td>\n",
       "      <td>-0.367016</td>\n",
       "      <td>0.507702</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.740877</td>\n",
       "      <td>-1.160417</td>\n",
       "      <td>-1.637830</td>\n",
       "      <td>2.172201</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        one       two     three      four key\n",
       "0  0.467976 -0.038649 -0.295344 -1.824726   L\n",
       "1 -0.358893  1.404453  0.704965 -0.200638   B\n",
       "2 -0.501840  0.659254 -0.421691 -0.057688   G\n",
       "3  0.204886  1.074134  1.388361 -0.982404   R\n",
       "4  0.354628 -0.133116  0.283763 -0.837063   Q\n",
       "5  1.817480  0.742273  0.419395 -2.251035   Q\n",
       "6 -0.776764  0.935518 -0.332872 -1.875641   U\n",
       "7 -0.913135  1.530624 -0.572657  0.477252   K\n",
       "8  0.358480 -0.497572 -0.367016  0.507702   S\n",
       "9 -1.740877 -1.160417 -1.637830  2.172201   G"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"examples/ex6.csv\", nrows=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fd55d9",
   "metadata": {},
   "source": [
    "#### Writing Data to Text Format\n",
    "Data can also be exported to a delimited format. Let’s consider one of the CSV files read before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "45fcf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"examples/ex5.csv\")\n",
    "data.to_csv(\"examples/out.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3226bc",
   "metadata": {},
   "source": [
    "Other delimiters can be used, of course (writing to sys.stdout so it prints the text result to the console rather than a file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f131aced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|something|a|b|c|d|message\n",
      "0|one|1|2|3.0|4|\n",
      "1|two|5|6||8|world\n",
      "2|three|9|10|11.0|12|foo\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "data.to_csv(sys.stdout, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffc754d",
   "metadata": {},
   "source": [
    "Missing values appear as empty strings in the output. You might want to denote them by some other sentinel value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "83dd6c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",something,a,b,c,d,message\n",
      "0,one,1,2,3.0,4,NULL\n",
      "1,two,5,6,NULL,8,world\n",
      "2,three,9,10,11.0,12,foo\n"
     ]
    }
   ],
   "source": [
    "data.to_csv(sys.stdout, na_rep=\"NULL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2471cc",
   "metadata": {},
   "source": [
    "With no other options specified, both the row and column labels are written. Both of these can be disabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "c299133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one,1,2,3.0,4,\n",
      "two,5,6,,8,world\n",
      "three,9,10,11.0,12,foo\n"
     ]
    }
   ],
   "source": [
    "data.to_csv(sys.stdout, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df380735",
   "metadata": {},
   "source": [
    "You can also write only a subset of the columns, and in an order of your choosing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "2ae6133a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a,b,c\n",
      "1,2,3.0\n",
      "5,6,\n",
      "9,10,11.0\n"
     ]
    }
   ],
   "source": [
    "data.to_csv(sys.stdout, index=False, columns=[\"a\", \"b\", \"c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c717b1",
   "metadata": {},
   "source": [
    "### JSON Data\n",
    "JSON (short for JavaScript Object Notation) has become one of the standard formats for sending data by HTTP request between web browsers and other applications. It is a much more free-form data format than a tabular text form like CSV. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bbe9930",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    " \"cities_lived\": [\"Akron\", \"Nashville\", \"New York\", \"San Francisco\"],\n",
    " \"pet\": null,\n",
    " \"siblings\": [{\"name\": \"Scott\", \"age\": 34, \"hobbies\": [\"guitars\", \"soccer\"]},\n",
    "              {\"name\": \"Katie\", \"age\": 42, \"hobbies\": [\"diving\", \"art\"]}]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0befe6",
   "metadata": {},
   "source": [
    "JSON is very nearly valid Python code with the exception of its null value null and some other nuances (such as disallowing trailing commas at the end of lists). The basic types are objects (dictionaries), arrays (lists), strings, numbers, Booleans, and nulls. All of the keys in an object must be strings. There are several Python libraries for reading and writing JSON data. I’ll use `json` here, as it is built into the Python standard library. To convert a JSON string to Python form, use `json.loads`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25a2b7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Wes',\n",
       " 'cities_lived': ['Akron', 'Nashville', 'New York', 'San Francisco'],\n",
       " 'pet': None,\n",
       " 'siblings': [{'name': 'Scott', 'age': 34, 'hobbies': ['guitars', 'soccer']},\n",
       "  {'name': 'Katie', 'age': 42, 'hobbies': ['diving', 'art']}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "result = json.loads(obj)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5147af",
   "metadata": {},
   "source": [
    "`json.dumps` converts a Python object back to JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1359a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"Wes\", \"cities_lived\": [\"Akron\", \"Nashville\", \"New York\", \"San Francisco\"], \"pet\": null, \"siblings\": [{\"name\": \"Scott\", \"age\": 34, \"hobbies\": [\"guitars\", \"soccer\"]}, {\"name\": \"Katie\", \"age\": 42, \"hobbies\": [\"diving\", \"art\"]}]}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asjson = json.dumps(result)\n",
    "\n",
    "asjson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81327ad",
   "metadata": {},
   "source": [
    "How you convert a JSON object or list of objects to a DataFrame or some other data structure for analysis will be up to you. Conveniently, you can pass a list of dictionaries (which were previously JSON objects) to the DataFrame constructor and select a subset of the data fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baa8f25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scott</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Katie</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age\n",
       "0  Scott   34\n",
       "1  Katie   42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siblings = pd.DataFrame(result[\"siblings\"], columns=[\"name\", \"age\"])\n",
    "\n",
    "siblings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df5d3e",
   "metadata": {},
   "source": [
    "The `pandas.read_json` can automatically convert JSON datasets in specific arrangements into a Series or DataFrame. For example:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90457ae1",
   "metadata": {},
   "source": [
    "!cat examples/example.json\n",
    "[{\"a\": 1, \"b\": 2, \"c\": 3},\n",
    " {\"a\": 4, \"b\": 5, \"c\": 6},\n",
    " {\"a\": 7, \"b\": 8, \"c\": 9}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b73f42",
   "metadata": {},
   "source": [
    "The default options for `pandas.read_json` assume that each object in the JSON array is a row in the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4caf85fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File examples/example.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexamples/example.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\json\\_json.py:791\u001b[39m, in \u001b[36mread_json\u001b[39m\u001b[34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient != \u001b[33m\"\u001b[39m\u001b[33mtable\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    789\u001b[39m     convert_axes = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m791\u001b[39m json_reader = \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\json\\_json.py:904\u001b[39m, in \u001b[36mJsonReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = filepath_or_buffer\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mujson\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28mself\u001b[39m._preprocess_data(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\json\\_json.py:960\u001b[39m, in \u001b[36mJsonReader._get_data_from_filepath\u001b[39m\u001b[34m(self, filepath_or_buffer)\u001b[39m\n\u001b[32m    952\u001b[39m     filepath_or_buffer = \u001b[38;5;28mself\u001b[39m.handles.handle\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    954\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    955\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer.lower().endswith(\n\u001b[32m   (...)\u001b[39m\u001b[32m    958\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[32m    959\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    962\u001b[39m     warnings.warn(\n\u001b[32m    963\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing literal json to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mread_json\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future version. To read from a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    967\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    968\u001b[39m     )\n",
      "\u001b[31mFileNotFoundError\u001b[39m: File examples/example.json does not exist"
     ]
    }
   ],
   "source": [
    "data = pd.read_json(\"examples/example.json\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bb7202",
   "metadata": {},
   "source": [
    "If you need to export data from pandas to JSON, one way is to use the to_json methods on Series and DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a30f582e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdata\u001b[49m.to_json(sys.stdout)\n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.to_json(sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b96c3",
   "metadata": {},
   "source": [
    "### Interacting with Web APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b5cf54",
   "metadata": {},
   "source": [
    "Many websites have public APIs providing data feeds via JSON or some other format. There are a number of ways to access these APIs from Python; one method that I recommend is the requests package, which can be installed with pip or conda:\n",
    "\n",
    "`pip install requests`\n",
    "\n",
    "To find the last 30 GitHub issues for pandas on GitHub, we can make a GET HTTP request using the add-on requests library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ef724d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feb40d11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.github.com', port=443): Max retries exceeded with url: /repos/pandas-dev/pandas/issues (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B0B25FA360>: Failed to resolve 'api.github.com' ([Errno 11001] getaddrinfo failed)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mgaierror\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\connection.py:60\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, label empty or too long\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     61\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:978\u001b[39m, in \u001b[36mgetaddrinfo\u001b[39m\u001b[34m(host, port, family, type, proto, flags)\u001b[39m\n\u001b[32m    977\u001b[39m addrlist = []\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    979\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[31mgaierror\u001b[39m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNameResolutionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:753\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    752\u001b[39m sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:205\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mNameResolutionError\u001b[39m: <urllib3.connection.HTTPSConnection object at 0x000001B0B25FA360>: Failed to resolve 'api.github.com' ([Errno 11001] getaddrinfo failed)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPSConnectionPool(host='api.github.com', port=443): Max retries exceeded with url: /repos/pandas-dev/pandas/issues (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B0B25FA360>: Failed to resolve 'api.github.com' ([Errno 11001] getaddrinfo failed)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m      2\u001b[39m url = \u001b[33m\"\u001b[39m\u001b[33mhttps://api.github.com/repos/pandas-dev/pandas/issues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m resp = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m resp.raise_for_status()\n\u001b[32m      5\u001b[39m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:677\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    673\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, _SSLError):\n\u001b[32m    674\u001b[39m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[32m    675\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n",
      "\u001b[31mConnectionError\u001b[39m: HTTPSConnectionPool(host='api.github.com', port=443): Max retries exceeded with url: /repos/pandas-dev/pandas/issues (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B0B25FA360>: Failed to resolve 'api.github.com' ([Errno 11001] getaddrinfo failed)\"))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = \"https://api.github.com/repos/pandas-dev/pandas/issues\"\n",
    "resp = requests.get(url)\n",
    "resp.raise_for_status()\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cc4462",
   "metadata": {},
   "source": [
    "It's a good practice to always call raise_for_status after using requests.get to check for HTTP errors.\n",
    "\n",
    "The response object’s json method will return a Python object containing the parsed JSON data as a dictionary or list (depending on what JSON is returned):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65bcd700",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m data = \u001b[43mresp\u001b[49m.json()\n",
      "\u001b[31mNameError\u001b[39m: name 'resp' is not defined"
     ]
    }
   ],
   "source": [
    "data = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e92c759a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdata\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "095d65ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DOC: Missing documentation for Series.__invert__() (~ operator)'"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125168e",
   "metadata": {},
   "source": [
    "Since the results retrieved are based on real-time data, what you see when you run this code will almost definitely be different.\n",
    "\n",
    "Each element in data is a dictionary containing all of the data found on a GitHub issue page (except for the comments). We can pass data directly to pandas.DataFrame and extract fields of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c30048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87ad9506",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m issues = pd.DataFrame(\u001b[43mdata\u001b[49m, columns=[\u001b[33m\"\u001b[39m\u001b[33mnumber\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      3\u001b[39m issues.to_csv(\u001b[33m\"\u001b[39m\u001b[33mexamples/teejay.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "issues = pd.DataFrame(data, columns=[\"number\", \"title\", \"labels\", \"state\"])\n",
    "\n",
    "issues.to_csv(\"examples/teejay.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778fcfa5",
   "metadata": {},
   "source": [
    "### Interacting with Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c33755",
   "metadata": {},
   "source": [
    "In a business setting, a lot of data may not be stored in text or Excel files. SQL-based relational databases (such as SQL Server, PostgreSQL, and MySQL) are in wide use, and many alternative databases have become quite popular. The choice of database is usually dependent on the performance, data integrity, and scalability needs of an application.\n",
    "\n",
    "pandas has some functions to simplify loading the results of a SQL query into a DataFrame. As an example, I’ll create a SQLite3 database using Python’s built-in sqlite3 driver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ac1166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1b0b3731140>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "query = \"\"\"\n",
    "CREATE TABLE test\n",
    "(a VARCHAR(20), b VARCHAR(20),\n",
    " c REAL,        d INTEGER\n",
    ");\"\"\"\n",
    "\n",
    "con = sqlite3.connect(\"mydata.sqlite\")\n",
    "\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6dbaf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c0bb9",
   "metadata": {},
   "source": [
    "Then, insert a few rows of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38cf4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"Atlanta\", \"Georgia\", 1.25, 6),\n",
    "         (\"Tallahassee\", \"Florida\", 2.6, 3),\n",
    "         (\"Sacramento\", \"California\", 1.7, 5)]\n",
    "\n",
    "stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\n",
    "\n",
    "con.executemany(stmt, data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec41b5a",
   "metadata": {},
   "source": [
    "Most Python SQL drivers return a list of tuples when selecting data from a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "97fa07c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Atlanta', 'Georgia', 1.25, 6),\n",
       " ('Tallahassee', 'Florida', 2.6, 3),\n",
       " ('Sacramento', 'California', 1.7, 5),\n",
       " ('Atlanta', 'Georgia', 1.25, 6),\n",
       " ('Tallahassee', 'Florida', 2.6, 3),\n",
       " ('Sacramento', 'California', 1.7, 5),\n",
       " ('Atlanta', 'Georgia', 1.25, 6),\n",
       " ('Tallahassee', 'Florida', 2.6, 3),\n",
       " ('Sacramento', 'California', 1.7, 5)]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = con.execute(\"SELECT * FROM test\")\n",
    "rows = cursor.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cef7ae0",
   "metadata": {},
   "source": [
    "You can pass the list of tuples to the DataFrame constructor, but you also need the column names, contained in the cursor’s description attribute. Note that for SQLite3, the cursor description only provides column names (the other fields, which are part of Python's Database API specification, are None), but for some other database drivers, more column information is provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "0df27048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('a', None, None, None, None, None, None),\n",
       " ('b', None, None, None, None, None, None),\n",
       " ('c', None, None, None, None, None, None),\n",
       " ('d', None, None, None, None, None, None))"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "4f27b9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>1.25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>California</td>\n",
       "      <td>1.70</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>1.25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>California</td>\n",
       "      <td>1.70</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>1.25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>California</td>\n",
       "      <td>1.70</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             a           b     c  d\n",
       "0      Atlanta     Georgia  1.25  6\n",
       "1  Tallahassee     Florida  2.60  3\n",
       "2   Sacramento  California  1.70  5\n",
       "3      Atlanta     Georgia  1.25  6\n",
       "4  Tallahassee     Florida  2.60  3\n",
       "5   Sacramento  California  1.70  5\n",
       "6      Atlanta     Georgia  1.25  6\n",
       "7  Tallahassee     Florida  2.60  3\n",
       "8   Sacramento  California  1.70  5"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rows, columns=[x[0] for x in cursor.description])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a29c1",
   "metadata": {},
   "source": [
    "This is quite a bit of munging that you’d rather not repeat each time you query the database. The SQLAlchemy project is a popular Python SQL toolkit that abstracts away many of the common differences between SQL databases. pandas has a read_sql function that enables you to read data easily from a general SQLAlchemy connection. You can install SQLAlchemy with conda like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3149c7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Downloading sqlalchemy-2.0.44-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy)\n",
      "  Downloading greenlet-3.2.4-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting typing-extensions>=4.6.0 (from sqlalchemy)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 2.4 MB/s  0:00:01\n",
      "Downloading greenlet-3.2.4-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: typing-extensions, greenlet, sqlalchemy\n",
      "\n",
      "   ------------- -------------------------- 1/3 [greenlet]\n",
      "   ------------- -------------------------- 1/3 [greenlet]\n",
      "   ------------- -------------------------- 1/3 [greenlet]\n",
      "   ------------- -------------------------- 1/3 [greenlet]\n",
      "   ------------- -------------------------- 1/3 [greenlet]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   -------------------------- ------------- 2/3 [sqlalchemy]\n",
      "   ---------------------------------------- 3/3 [sqlalchemy]\n",
      "\n",
      "Successfully installed greenlet-3.2.4 sqlalchemy-2.0.44 typing-extensions-4.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a473936",
   "metadata": {},
   "source": [
    "Now, we'll connect to the same SQLite database with SQLAlchemy and read data from the table created before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7fbfef15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>1.25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>California</td>\n",
       "      <td>1.70</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>1.25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>California</td>\n",
       "      <td>1.70</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>1.25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>California</td>\n",
       "      <td>1.70</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             a           b     c  d\n",
       "0      Atlanta     Georgia  1.25  6\n",
       "1  Tallahassee     Florida  2.60  3\n",
       "2   Sacramento  California  1.70  5\n",
       "3      Atlanta     Georgia  1.25  6\n",
       "4  Tallahassee     Florida  2.60  3\n",
       "5   Sacramento  California  1.70  5\n",
       "6      Atlanta     Georgia  1.25  6\n",
       "7  Tallahassee     Florida  2.60  3\n",
       "8   Sacramento  California  1.70  5"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlalchemy as sqla\n",
    "\n",
    "db = sqla.create_engine(\"sqlite:///mydata.sqlite\")\n",
    "pd.read_sql(\"SELECT * FROM test\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40162375",
   "metadata": {},
   "source": [
    "### Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a58d84",
   "metadata": {},
   "source": [
    "During the course of doing data analysis and modeling, a significant amount of time is spent on data preparation: loading, cleaning, transforming, and rearranging. Such tasks are often reported to take up 80% or more of an analyst's time. Sometimes the way that data is stored in files or databases is not in the right format for a particular task. Many researchers choose to do ad hoc processing of data from one form to another using a general-purpose programming language, like Python, Perl, R, or Java, or Unix text-processing tools like sed or awk. Fortunately, pandas, along with the built-in Python language features, provides you with a high-level, flexible, and fast set of tools to enable you to manipulate data into the right form.\n",
    "\n",
    "If you identify a type of data manipulation that isn’t anywhere in this book or elsewhere in the pandas library, feel free to share your use case on one of the Python mailing lists or on the pandas GitHub site. Indeed, much of the design and implementation of pandas have been driven by the needs of real-world applications.\n",
    "\n",
    "In this chapter I discuss tools for missing data, duplicate data, string manipulation, and some other analytical data transformations. In the next chapter, I focus on combining and rearranging datasets in various ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac452bf",
   "metadata": {},
   "source": [
    "#### Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f74416",
   "metadata": {},
   "source": [
    "Missing data occurs commonly in many data analysis applications. One of the goals of pandas is to make working with missing data as painless as possible. For example, all of the descriptive statistics on pandas objects exclude missing data by default.\n",
    "\n",
    "The way that missing data is represented in pandas objects is somewhat imperfect, but it is sufficient for most real-world use. For data with float64 dtype, pandas uses the floating-point value NaN (Not a Number) to represent missing data.\n",
    "\n",
    "We call this a sentinel value: when present, it indicates a missing (or null) value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "654e56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_data = pd.Series([1.2, -3.5, np.nan, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "e21bfba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.2\n",
       "1   -3.5\n",
       "2    NaN\n",
       "3    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3fa936",
   "metadata": {},
   "source": [
    "The isna method gives us a Boolean Series with True where values are null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "c48d6199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_data.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13e850",
   "metadata": {},
   "source": [
    "In pandas, we've adopted a convention used in the R programming language by referring to missing data as NA, which stands for not available. In statistics applications, NA data may either be data that does not exist or that exists but was not observed (through problems with data collection, for example). When cleaning up data for analysis, it is often important to do analysis on the missing data itself to identify data collection problems or potential biases in the data caused by missing data.\n",
    "\n",
    "The built-in Python None value is also treated as NA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "57db8f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2     True\n",
       "3    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_data = pd.Series([\"aardvark\", np.nan, None, \"avocado\"])\n",
    "string_data.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d596a5",
   "metadata": {},
   "source": [
    "The pandas project has attempted to make working with missing data consistent across data types. Functions like pandas.isna abstract away many of the annoying details. See Table 7.1 for a list of some functions related to missing data handling.\n",
    "\n",
    "#### NA handling object methods\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `dropna` | Filter axis labels based on whether values for each label have missing data, with varying thresholds for how much missing data to tolerate. |\n",
    "| `fillna` | Fill in missing data with some value or using an interpolation method such as `\"ffill\"` or `\"bfill\"`. |\n",
    "| `isna` | Return Boolean values indicating which values are missing/NA. |\n",
    "| `notna` | Negation of `isna`; returns `True` for non-NA values and `False` for NA values. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc48c97",
   "metadata": {},
   "source": [
    "#### Filtering Out Missing Data\n",
    "There are a few ways to filter out missing data. While you always have the option to do it by hand using pandas.isna and Boolean indexing, dropna can be helpful. On a Series, it returns the Series with only the nonnull data and index values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "7197c0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "2    3.5\n",
       "4    7.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.Series([1, np.nan, 3.5, np.nan, 7])\n",
    "data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a630b63",
   "metadata": {},
   "source": [
    "This is the same thing as doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "873d775f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "2    3.5\n",
       "4    7.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f9f82",
   "metadata": {},
   "source": [
    "With DataFrame objects, there are different ways to remove missing data. You may want to drop rows or columns that are all NA, or only those rows or columns containing any NAs at all. dropna by default drops any row containing a missing value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "40b21339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  1.0  6.5  3.0"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame([[1., 6.5, 3.], [1., np.nan, np.nan], [np.nan, np.nan, np.nan], [np.nan, 6.5, 3.]])\n",
    "data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9269b999",
   "metadata": {},
   "source": [
    "Passing how=\"all\" will drop only rows that are all NA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0230c7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  1.0  6.5  3.0\n",
       "1  1.0  NaN  NaN\n",
       "2  NaN  NaN  NaN\n",
       "3  NaN  6.5  3.0"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "56dd3fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  1.0  6.5  3.0\n",
       "1  1.0  NaN  NaN\n",
       "3  NaN  6.5  3.0"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e1a5b",
   "metadata": {},
   "source": [
    "Keep in mind that these functions return new objects by default and do not modify the contents of the original object.\n",
    "\n",
    "To drop columns in the same way, pass axis=\"columns\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "10631576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2   4\n",
       "0  1.0  6.5  3.0 NaN\n",
       "1  1.0  NaN  NaN NaN\n",
       "2  NaN  NaN  NaN NaN\n",
       "3  NaN  6.5  3.0 NaN"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[4] = np.nan\n",
    "\n",
    "data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b0c2c15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  1.0  6.5  3.0\n",
       "1  1.0  NaN  NaN\n",
       "2  NaN  NaN  NaN\n",
       "3  NaN  6.5  3.0"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(axis=\"columns\", how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aa553d",
   "metadata": {},
   "source": [
    "Suppose you want to keep only rows containing at most a certain number of missing observations. You can indicate this with the thresh argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "4507cfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2\n",
      "0  2.040950       NaN       NaN\n",
      "1  0.373144       NaN       NaN\n",
      "2 -1.704707       NaN -1.056701\n",
      "3 -0.370714       NaN  0.983587\n",
      "4  1.636196  0.073746 -1.638427\n",
      "5  1.563269 -1.494755 -0.227718\n",
      "6 -0.650784 -0.820741 -0.977512\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.standard_normal((7, 3)))\n",
    "df.iloc[:4, 1] = np.nan\n",
    "df.iloc[:2, 2] = np.nan\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "69646f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.636196</td>\n",
       "      <td>0.073746</td>\n",
       "      <td>-1.638427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.563269</td>\n",
       "      <td>-1.494755</td>\n",
       "      <td>-0.227718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.650784</td>\n",
       "      <td>-0.820741</td>\n",
       "      <td>-0.977512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "4  1.636196  0.073746 -1.638427\n",
       "5  1.563269 -1.494755 -0.227718\n",
       "6 -0.650784 -0.820741 -0.977512"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "dc4ffe0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.704707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.056701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.370714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.636196</td>\n",
       "      <td>0.073746</td>\n",
       "      <td>-1.638427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.563269</td>\n",
       "      <td>-1.494755</td>\n",
       "      <td>-0.227718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.650784</td>\n",
       "      <td>-0.820741</td>\n",
       "      <td>-0.977512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "2 -1.704707       NaN -1.056701\n",
       "3 -0.370714       NaN  0.983587\n",
       "4  1.636196  0.073746 -1.638427\n",
       "5  1.563269 -1.494755 -0.227718\n",
       "6 -0.650784 -0.820741 -0.977512"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(thresh=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6e462c",
   "metadata": {},
   "source": [
    "#### Filling In Missing Data\n",
    "Rather than filtering out missing data (and potentially discarding other data along with it), you may want to fill in the “holes” in any number of ways. For most purposes, the fillna method is the workhorse function to use. Calling fillna with a constant replaces missing values with that value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f3101a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.040950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.373144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.704707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.056701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.370714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.636196</td>\n",
       "      <td>0.073746</td>\n",
       "      <td>-1.638427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.563269</td>\n",
       "      <td>-1.494755</td>\n",
       "      <td>-0.227718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.650784</td>\n",
       "      <td>-0.820741</td>\n",
       "      <td>-0.977512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  2.040950  0.000000  0.000000\n",
       "1  0.373144  0.000000  0.000000\n",
       "2 -1.704707  0.000000 -1.056701\n",
       "3 -0.370714  0.000000  0.983587\n",
       "4  1.636196  0.073746 -1.638427\n",
       "5  1.563269 -1.494755 -0.227718\n",
       "6 -0.650784 -0.820741 -0.977512"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fc2b70",
   "metadata": {},
   "source": [
    "Calling fillna with a dictionary, you can use a different fill value for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "1ca6b23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.040950</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.373144</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.704707</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-1.056701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.370714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.983587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.636196</td>\n",
       "      <td>0.073746</td>\n",
       "      <td>-1.638427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.563269</td>\n",
       "      <td>-1.494755</td>\n",
       "      <td>-0.227718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.650784</td>\n",
       "      <td>-0.820741</td>\n",
       "      <td>-0.977512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  2.040950  0.500000  0.000000\n",
       "1  0.373144  0.500000  0.000000\n",
       "2 -1.704707  0.500000 -1.056701\n",
       "3 -0.370714  0.500000  0.983587\n",
       "4  1.636196  0.073746 -1.638427\n",
       "5  1.563269 -1.494755 -0.227718\n",
       "6 -0.650784 -0.820741 -0.977512"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna({1: 0.5, 2: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d0ca41",
   "metadata": {},
   "source": [
    "The same interpolation methods available for reindexing (see Table 5.3) can be used with fillna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "2497713a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2\n",
      "0 -0.745716  0.439531  0.703067\n",
      "1  1.205190 -0.347581  0.317678\n",
      "2 -0.901683       NaN -0.526896\n",
      "3  0.810781       NaN -1.113451\n",
      "4 -0.033441       NaN       NaN\n",
      "5 -1.295903       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.standard_normal((6, 3)))\n",
    "df.iloc[2:, 1] = np.nan\n",
    "df.iloc[4:, 2] = np.nan\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "cdebed05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IBRAHEEM\\AppData\\Local\\Temp\\ipykernel_18512\\3944122520.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method=\"ffill\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.745716</td>\n",
       "      <td>0.439531</td>\n",
       "      <td>0.703067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.205190</td>\n",
       "      <td>-0.347581</td>\n",
       "      <td>0.317678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.901683</td>\n",
       "      <td>-0.347581</td>\n",
       "      <td>-0.526896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.810781</td>\n",
       "      <td>-0.347581</td>\n",
       "      <td>-1.113451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.033441</td>\n",
       "      <td>-0.347581</td>\n",
       "      <td>-1.113451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.295903</td>\n",
       "      <td>-0.347581</td>\n",
       "      <td>-1.113451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0 -0.745716  0.439531  0.703067\n",
       "1  1.205190 -0.347581  0.317678\n",
       "2 -0.901683 -0.347581 -0.526896\n",
       "3  0.810781 -0.347581 -1.113451\n",
       "4 -0.033441 -0.347581 -1.113451\n",
       "5 -1.295903 -0.347581 -1.113451"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "6e8aa285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IBRAHEEM\\AppData\\Local\\Temp\\ipykernel_18512\\1627181726.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method=\"ffill\", limit=2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.745716</td>\n",
       "      <td>0.439531</td>\n",
       "      <td>0.703067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.205190</td>\n",
       "      <td>-0.347581</td>\n",
       "      <td>0.317678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.901683</td>\n",
       "      <td>-0.347581</td>\n",
       "      <td>-0.526896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.810781</td>\n",
       "      <td>-0.347581</td>\n",
       "      <td>-1.113451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.033441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.113451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.295903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.113451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0 -0.745716  0.439531  0.703067\n",
       "1  1.205190 -0.347581  0.317678\n",
       "2 -0.901683 -0.347581 -0.526896\n",
       "3  0.810781 -0.347581 -1.113451\n",
       "4 -0.033441       NaN -1.113451\n",
       "5 -1.295903       NaN -1.113451"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(method=\"ffill\", limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd3656",
   "metadata": {},
   "source": [
    "With fillna you can do lots of other things such as simple data imputation using the median or mean statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbfcd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.000000\n",
       "1    3.833333\n",
       "2    3.500000\n",
       "3    3.833333\n",
       "4    7.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.Series([1., np.nan, 3.5, np.nan, 7]) \n",
    "data.fillna(data.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b74d0",
   "metadata": {},
   "source": [
    "#### `fillna` function arguments:\n",
    "| Argument | Description |\n",
    "|----------|-------------|\n",
    "| `value` | Scalar value or dictionary-like object to use to fill missing values |\n",
    "| `method` | Interpolation method: one of `\"bfill\"` (backward fill) or `\"ffill\"` (forward fill); default is `None` |\n",
    "| `axis` | Axis to fill on (`\"index\"` or `\"columns\"`); default is `axis=\"index\"` |\n",
    "| `limit` | For forward and backward filling, maximum number of consecutive periods to fill |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a9d97d",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48487edc",
   "metadata": {},
   "source": [
    "So far in this chapter we’ve been concerned with handling missing data. Filtering, cleaning, and other transformations are another class of important operations.\n",
    "\n",
    "#### Removing Duplicates\n",
    "Duplicate rows may be found in a DataFrame for any number of reasons. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38978605",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"k1\": [\"one\", \"two\"] * 3 + [\"two\"], \"k2\": [1, 1, 2, 3, 3, 4, 4]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40082b0d",
   "metadata": {},
   "source": [
    "The DataFrame method duplicated returns a Boolean Series indicating whether each row is a duplicate (its column values are exactly equal to those in an earlier row) or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8865a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1208acef",
   "metadata": {},
   "source": [
    "Relatedly, drop_duplicates returns a DataFrame with rows where the duplicated array is False filtered out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d9b202",
   "metadata": {},
   "source": [
    "Both methods by default consider all of the columns; alternatively, you can specify any subset of them to detect duplicates. Suppose we had an additional column of values and wanted to filter duplicates based only on the \"k1\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"v1\"] = range(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b64172",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6981f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=\"k1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0c64b",
   "metadata": {},
   "source": [
    "#### Transforming Data Using a Function or Mapping\n",
    "For many datasets, you may wish to perform some transformation based on the values in an array, Series, or column in a DataFrame. Consider the following hypothetical data collected about various kinds of meat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "524ee732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d0c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"food\": [\"bacon\", \"pulled pork\", \"bacon\", \"pastrami\", \"corned beef\", \"bacon\", \"pastrami\", \"honey ham\", \"nova lox\"], \"ounces\": [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b88ac86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food</th>\n",
       "      <th>ounces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacon</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pulled pork</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacon</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pastrami</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corned beef</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bacon</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pastrami</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>honey ham</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nova lox</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          food  ounces\n",
       "0        bacon     4.0\n",
       "1  pulled pork     3.0\n",
       "2        bacon    12.0\n",
       "3     pastrami     6.0\n",
       "4  corned beef     7.5\n",
       "5        bacon     8.0\n",
       "6     pastrami     3.0\n",
       "7    honey ham     5.0\n",
       "8     nova lox     6.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771397eb",
   "metadata": {},
   "source": [
    "Suppose you wanted to add a column indicating the type of animal that each food came from. Let’s write down a mapping of each distinct meat type to the kind of animal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a719b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_to_animal = {\n",
    "  \"bacon\": \"pig\",\n",
    "  \"pulled pork\": \"pig\",\n",
    "  \"pastrami\": \"cow\",\n",
    "  \"corned beef\": \"cow\",\n",
    "  \"honey ham\": \"pig\",\n",
    "  \"nova lox\": \"salmon\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2434d58a",
   "metadata": {},
   "source": [
    "The `map` method on a Series accepts a function or dictionary-like object containing a mapping to do the transformation of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f88ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food</th>\n",
       "      <th>ounces</th>\n",
       "      <th>animal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacon</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pulled pork</td>\n",
       "      <td>3.0</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacon</td>\n",
       "      <td>12.0</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pastrami</td>\n",
       "      <td>6.0</td>\n",
       "      <td>cow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corned beef</td>\n",
       "      <td>7.5</td>\n",
       "      <td>cow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bacon</td>\n",
       "      <td>8.0</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pastrami</td>\n",
       "      <td>3.0</td>\n",
       "      <td>cow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>honey ham</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nova lox</td>\n",
       "      <td>6.0</td>\n",
       "      <td>salmon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          food  ounces  animal\n",
       "0        bacon     4.0     pig\n",
       "1  pulled pork     3.0     pig\n",
       "2        bacon    12.0     pig\n",
       "3     pastrami     6.0     cow\n",
       "4  corned beef     7.5     cow\n",
       "5        bacon     8.0     pig\n",
       "6     pastrami     3.0     cow\n",
       "7    honey ham     5.0     pig\n",
       "8     nova lox     6.0  salmon"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"animal\"] = data[\"food\"].map(meat_to_animal)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a4626a",
   "metadata": {},
   "source": [
    "We could also have passed a function that does all the work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46403867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food</th>\n",
       "      <th>ounces</th>\n",
       "      <th>animal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacon</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pulled pork</td>\n",
       "      <td>3.0</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacon</td>\n",
       "      <td>12.0</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pastrami</td>\n",
       "      <td>6.0</td>\n",
       "      <td>cow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corned beef</td>\n",
       "      <td>7.5</td>\n",
       "      <td>cow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bacon</td>\n",
       "      <td>8.0</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pastrami</td>\n",
       "      <td>3.0</td>\n",
       "      <td>cow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>honey ham</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nova lox</td>\n",
       "      <td>6.0</td>\n",
       "      <td>salmon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          food  ounces  animal\n",
       "0        bacon     4.0     pig\n",
       "1  pulled pork     3.0     pig\n",
       "2        bacon    12.0     pig\n",
       "3     pastrami     6.0     cow\n",
       "4  corned beef     7.5     cow\n",
       "5        bacon     8.0     pig\n",
       "6     pastrami     3.0     cow\n",
       "7    honey ham     5.0     pig\n",
       "8     nova lox     6.0  salmon"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_animal(x):\n",
    "    return meat_to_animal[x]\n",
    "\n",
    "data[\"animal\"] = data[\"food\"].map(get_animal)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f61a511",
   "metadata": {},
   "source": [
    "Using map is a convenient way to perform element-wise transformations and other data cleaning-related operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac82dda",
   "metadata": {},
   "source": [
    "#### Replacing Values\n",
    "Filling in missing data with the fillna method is a special case of more general value replacement. As you've already seen, map can be used to modify a subset of values in an object, but replace provides a simpler and more flexible way to do so. Let’s consider this Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([1., -999., 2., -999., -1000., 3.])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c46c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(-999, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebf714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([-999, -1000], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02282b2",
   "metadata": {},
   "source": [
    "To use a different replacement for each value, pass a list of substitutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf69d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([-999, -1000], [np.nan, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3486ee6",
   "metadata": {},
   "source": [
    "The argument passed can also be a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d50f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace({-999: np.nan, -1000: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c200006d",
   "metadata": {},
   "source": [
    "#### Renaming Axis Indexes\n",
    "Like values in a Series, axis labels can be similarly transformed by a function or mapping of some form to produce new, differently labeled objects. You can also modify the axes in place without creating a new data structure. Here’s a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)), index=[\"Ohio\", \"Colorado\", \"New York\"], columns=[\"one\", \"two\", \"three\", \"four\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ccf41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    return x[:4].upper()\n",
    "data.index.map(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4412622",
   "metadata": {},
   "source": [
    "You can assign to the index attribute, modifying the DataFrame in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = data.index.map(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a1357",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c088ad8f",
   "metadata": {},
   "source": [
    "If you want to create a transformed version of a dataset without modifying the original, a useful method is rename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d52172",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(index=str.lower, columns=str.upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaa1c01",
   "metadata": {},
   "source": [
    "Notably, rename can be used in conjunction with a dictionary-like object, providing new values for a subset of the axis labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79dc74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(index={\"OHIO\": \"INDIANA\"}, columns={\"three\": \"peekaboo\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758eb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f63b354",
   "metadata": {},
   "source": [
    "#### Discretization and Binning\n",
    "Continuous data is often discretized or otherwise separated into “bins” for analysis. Suppose you have data about a group of people in a study, and you want to group them into discrete age buckets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f5f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec39fe3",
   "metadata": {},
   "source": [
    "Let’s divide these into bins of 18 to 25, 26 to 35, 36 to 60, and finally 61 and older. To do so, you have to use `pandas.cut`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ff410",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [18, 25, 35, 60, 100]\n",
    "age_categories = pd.cut(ages, bins)\n",
    "age_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ed1a3",
   "metadata": {},
   "source": [
    "The object pandas returns is a special Categorical object. The output you see describes the bins computed by `pandas.cut`. Each bin is identified by a special (unique to pandas) interval value type containing the lower and upper limit of each bin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7965c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_categories.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae21301",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_categories.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00367042",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_categories.categories[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f3b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(age_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0465d6b",
   "metadata": {},
   "source": [
    "You can override the default interval-based bin labeling by passing a list or array to the labels option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85992750",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = [\"Youth\", \"YoungAdult\", \"MiddleAged\", \"Senior\"]\n",
    "\n",
    "pd.cut(ages, bins, labels=group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66efa9f",
   "metadata": {},
   "source": [
    "### Grouping and Pivot tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04932ad2",
   "metadata": {},
   "source": [
    "--------------------------------------------------\n",
    "0.  Setup (one cell)\n",
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd6b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127dde3",
   "metadata": {},
   "source": [
    "1.  Toy data – keep it tiny so the output fits on one slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4917b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Region' : ['North', 'North', 'South', 'South', 'East', 'East'],\n",
    "    'Product': ['Apple', 'Banana', 'Apple', 'Banana', 'Apple', 'Banana'],\n",
    "    'Qtr'    : ['Q1', 'Q2', 'Q1', 'Q2', 'Q1', 'Q2'],\n",
    "    'Sales'  : [100, 150, 120, 90, 80, 110],\n",
    "    'Units'  : [10, 15, 12, 9, 8, 11]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab847899",
   "metadata": {},
   "source": [
    "2.  groupby – “split → apply → combine” in one lin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4ceef9",
   "metadata": {},
   "source": [
    "\n",
    "a. **Total sales per region**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Region')['Sales'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dcce19",
   "metadata": {},
   "source": [
    "b. **Multiple metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f0e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Region').agg({'Sales': 'sum', 'Units': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9a0096",
   "metadata": {},
   "source": [
    "c. **Two-level index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d03fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Region', 'Product'])['Sales'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f976a954",
   "metadata": {},
   "source": [
    "3.  pivot_table – “groupby + reshape”\n",
    "\n",
    "Same result as (c) but **wide** (Region → rows, Product → columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e318975",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = pd.pivot_table(df,\n",
    "               values='Sales',\n",
    "               index='Region',\n",
    "               columns='Product',\n",
    "               aggfunc='sum',\n",
    "               fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4352396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5414e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d8795",
   "metadata": {},
   "source": [
    "Add **margins** (Excel-style grand totals):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1cac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values='Sales', index='Region', columns='Product',\n",
    "               aggfunc='sum', fill_value=0, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485553b3",
   "metadata": {},
   "source": [
    "Multiple value fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd290c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values=['Sales', 'Units'],\n",
    "               index='Region', columns='Product',\n",
    "               aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902d7d97",
   "metadata": {},
   "source": [
    "4.  pivot – “pure reshape, no aggregation”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a816a",
   "metadata": {},
   "source": [
    "Use when **index + column combination is unique** (no duplicates).\n",
    "\n",
    "Example: long → wide for **Qtr** (unique per Region-Product pair):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7acadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot(index=['Region', 'Product'],\n",
    "         columns='Qtr',\n",
    "         values='Sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d88782",
   "metadata": {},
   "source": [
    "### 1.  What merge does\n",
    "Combines rows from two DataFrames **side-by-side** by matching values in **one or more key columns** – exactly like a SQL JOIN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ade452",
   "metadata": {},
   "source": [
    "### 2.  The four common joins (picture = SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53967fa9",
   "metadata": {},
   "source": [
    "```python\n",
    "pd.merge(left, right, how='inner', on='key')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab11646",
   "metadata": {},
   "source": [
    "| `how=` | Keep rows that… | Venn mental pic |\n",
    "|--------|------------------|-----------------|\n",
    "| `inner` | **match in BOTH tables** | ∩ intersection |\n",
    "| `left` | **match in LEFT** (+ keep all left rows) | ← full left |\n",
    "| `right` | **match in RIGHT** (+ keep all right rows) | → full right |\n",
    "| `outer` | **match in EITHER** (+ keep ALL rows) | ∪ union |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe601bb9",
   "metadata": {},
   "source": [
    "Imagine two small tables:\n",
    "\n",
    "**Table A (left)**  \n",
    "| id | name |\n",
    "|----|------|\n",
    "| 1  | Ann  |\n",
    "| 2  | Bob  |\n",
    "\n",
    "**Table B (right)**  \n",
    "| id | city  |\n",
    "|----|-------|\n",
    "| 1  | Paris |\n",
    "| 3  | Rome  |\n",
    "\n",
    "---\n",
    "\n",
    "### 1. INNER join  \n",
    "**Keep only the rows that match in BOTH tables.**  \n",
    "→ Result:  \n",
    "| id | name | city  |\n",
    "|----|------|-------|\n",
    "| 1  | Ann  | Paris |\n",
    "\n",
    "---\n",
    "\n",
    "### 2. LEFT join  \n",
    "**Keep every row from Table A;**  \n",
    "if a row has **no match** in B, fill with **NaN**.  \n",
    "→ Result:  \n",
    "| id | name | city  |\n",
    "|----|------|-------|\n",
    "| 1  | Ann  | Paris |\n",
    "| 2  | Bob  | NaN   |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. RIGHT join  \n",
    "**Keep every row from Table B;**  \n",
    "if a row has **no match** in A, fill with **NaN**.  \n",
    "→ Result:  \n",
    "| id | name | city  |\n",
    "|----|------|-------|\n",
    "| 1  | Ann  | Paris |\n",
    "| 3  | NaN  | Rome  |\n",
    "\n",
    "---\n",
    "\n",
    "**One-sentence summary:**  \n",
    "- **Inner** = overlap only  \n",
    "- **Left** = all from **first** table  \n",
    "- **Right** = all from **second** table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cfd13b",
   "metadata": {},
   "source": [
    "### 3.  Smallest working example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58234d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "users = pd.DataFrame({'user_id': [1, 2, 3], 'name': ['Ann', 'Bob', 'Cat']})\n",
    "orders = pd.DataFrame({'user_id': [1, 1, 2], 'amount': [10, 20, 30]})\n",
    "\n",
    "pd.merge(users, orders, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae48301",
   "metadata": {},
   "source": [
    "### 4.  Must-know arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5436c036",
   "metadata": {},
   "source": [
    "| Arg | Meaning |\n",
    "|-----|---------|\n",
    "| `on=` | Single column name **common to both** (or list). |\n",
    "| `left_on=` / `right_on=` | Use when column names **differ** between tables. |\n",
    "| `left_index=True` / `right_index=True` | Merge on **index labels** instead of columns. |\n",
    "| `suffixes=('', '_right')` | String to append **when same column names exist** (avoids `name_x`, `name_y`). |\n",
    "| `validate='1:m'` | Safety check: `'1:1'`, `'1:m'`, `'m:1'`, `'m:m'` – raises error if assumption broken. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3315f40",
   "metadata": {},
   "source": [
    "### 5.  Quick reference card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fc9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key': ['A', 'B', 'C'], 'val1': [1, 2, 3]})\n",
    "df2 = pd.DataFrame({'key': ['A', 'B', 'D'], 'val2': [4, 5, 6]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98eef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same name\n",
    "# Check for the inner, left, right and outer\n",
    "pd.merge(df1, df2, on='key', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc308d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key1': ['A', 'B', 'C'], 'val1': [1, 2, 3]})\n",
    "df2 = pd.DataFrame({'key2': ['A', 'B', 'D'], 'val2': [4, 5, 6]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d68b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different names\n",
    "pd.merge(df1, df2, left_on='key1', right_on='key2', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2bfaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index join\n",
    "pd.merge(df1, df2, left_index=True, right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3994bc",
   "metadata": {},
   "source": [
    "#### 1.  What concat does\n",
    "Stacks or appends DataFrames **along one axis** – no matching required.  \n",
    "Think **“glue”** instead of **“lock-and-key”**.\n",
    "\n",
    "- `axis=0` ➜ **row-wise** (top-to-bottom) – **default**  \n",
    "- `axis=1` ➜ **column-wise** (side-by-side) – like **bind-cols**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c011b69",
   "metadata": {},
   "source": [
    "#### 2.  Smallest demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb448e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'id': [1, 2], 'val': ['A', 'B']})\n",
    "df2 = pd.DataFrame({'id': [3, 4], 'val': ['C', 'D']})\n",
    "\n",
    "pd.concat([df1, df2])          # axis=0 (row-wise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735ac5f",
   "metadata": {},
   "source": [
    "##### Column-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88756ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8da4b63",
   "metadata": {},
   "source": [
    "\n",
    "### 3.  Must-know arguments\n",
    "| Arg | What it does |\n",
    "|-----|--------------|\n",
    "| `objs=[df1, df2, ...]` | **List/tuple** of DataFrames/Series to glue. |\n",
    "| `axis=0` | `0` or `'index'` = rows; `1` or `'columns'` = columns. |\n",
    "| `ignore_index=False` | If `True`, re-label rows 0, 1, 2, … (removes duplicate index). |\n",
    "| `keys=['A','B']` | Creates **extra index level** so you can tell which chunk each row came from (handy for groupby later). |\n",
    "| `join='outer'` | When `axis=1`, keep **union** of columns (`outer`, default) or **intersection** (`inner`). |\n",
    "| `verify_integrity=False` | If `True`, raise error on **duplicate index** (safety check). |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
